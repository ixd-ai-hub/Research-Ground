{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixd-ai-hub/Research-Ground/blob/feature%2FCU-865d7mpad-sticker-generation-models/mlops/controlnet_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlHLyKCM2zkf",
        "outputId": "39b3d9ad-60eb-4901-8ca7-d0211ba63db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  2 12:32:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda_11.7.0_515.43.04_linux.run\n",
        "!sudo sh cuda_11.7.0_515.43.04_linux.run -y\n",
        "!python -c 'exec(\"import torch\\nprint(torch.__version__)\")'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMKlpBzUITGj",
        "outputId": "00f021ad-7ef2-4d80-886c-6b815dbbc065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sh: 0: Can't open cuda_11.7.0_515.43.04_linux.run\n",
            "2.0.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers==0.0.16rc425\n",
        "!pip install triton\n",
        "!python -m xformers.info output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxp6bibYLM-1",
        "outputId": "08de87c5-a1cf-450f-9751-2671e9e10edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xformers==0.0.16rc425\n",
            "  Downloading xformers-0.0.16rc425-cp310-cp310-manylinux2014_x86_64.whl (50.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.16rc425) (1.22.4)\n",
            "Collecting pyre-extensions==0.0.23 (from xformers==0.0.16rc425)\n",
            "  Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n",
            "Collecting torch==1.13.1 (from xformers==0.0.16rc425)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect (from pyre-extensions==0.0.23->xformers==0.0.16rc425)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.23->xformers==0.0.16rc425) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->xformers==0.0.16rc425)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->xformers==0.0.16rc425)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->xformers==0.0.16rc425)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->xformers==0.0.16rc425)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->xformers==0.0.16rc425) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->xformers==0.0.16rc425) (0.40.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions==0.0.23->xformers==0.0.16rc425)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, mypy-extensions, typing-inspect, nvidia-cudnn-cu11, torch, pyre-extensions, xformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mypy-extensions-1.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pyre-extensions-0.0.23 torch-1.13.1 typing-inspect-0.8.0 xformers-0.0.16rc425\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from triton) (1.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton) (16.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->triton) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->triton) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->triton) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->triton) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->triton) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->triton) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->triton) (0.40.0)\n",
            "xFormers 0.0.16rc425\n",
            "memory_efficient_attention.cutlassF:               available\n",
            "memory_efficient_attention.cutlassB:               available\n",
            "memory_efficient_attention.flshattF:               available\n",
            "memory_efficient_attention.flshattB:               available\n",
            "memory_efficient_attention.smallkF:                available\n",
            "memory_efficient_attention.smallkB:                available\n",
            "memory_efficient_attention.tritonflashattF:        available\n",
            "memory_efficient_attention.tritonflashattB:        available\n",
            "swiglu.fused.p.cpp:                                available\n",
            "is_triton_available:                               True\n",
            "is_functorch_available:                            False\n",
            "pytorch.version:                                   1.13.1+cu117\n",
            "pytorch.cuda:                                      available\n",
            "gpu.compute_capability:                            7.5\n",
            "gpu.name:                                          Tesla T4\n",
            "build.info:                                        available\n",
            "build.cuda_version:                                1107\n",
            "build.python_version:                              3.10.9\n",
            "build.torch_version:                               1.13.1+cu117\n",
            "build.env.TORCH_CUDA_ARCH_LIST:                    5.0+PTX 6.0 6.1 7.0 7.5 8.0 8.6\n",
            "build.env.XFORMERS_BUILD_TYPE:                     Release\n",
            "build.env.XFORMERS_ENABLE_DEBUG_ASSERTIONS:        None\n",
            "build.env.NVCC_FLAGS:                              None\n",
            "build.env.XFORMERS_PACKAGE_FROM:                   wheel-v0.0.16rc425\n",
            "source.privacy:                                    open source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBbcB4vwj_jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e94d1f6-b5c0-466d-fb9c-86af57cade9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi==0.90.1\n",
            "  Downloading fastapi-0.90.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.90.1) (1.10.7)\n",
            "Collecting starlette<0.24.0,>=0.22.0 (from fastapi==0.90.1)\n",
            "  Downloading starlette-0.23.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.90.1) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.24.0,>=0.22.0->fastapi==0.90.1) (3.6.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.24.0,>=0.22.0->fastapi==0.90.1) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.24.0,>=0.22.0->fastapi==0.90.1) (1.3.0)\n",
            "Installing collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.90.1 starlette-0.23.1\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 18962, done.\u001b[K\n",
            "remote: Counting objects: 100% (556/556), done.\u001b[K\n",
            "remote: Compressing objects: 100% (236/236), done.\u001b[K\n",
            "remote: Total 18962 (delta 342), reused 479 (delta 320), pack-reused 18406\u001b[K\n",
            "Receiving objects: 100% (18962/18962), 28.89 MiB | 30.88 MiB/s, done.\n",
            "Resolving deltas: 100% (13216/13216), done.\n",
            "Cloning into '/content/stable-diffusion-webui/extensions/sd-webui-controlnet'...\n",
            "remote: Enumerating objects: 5825, done.\u001b[K\n",
            "remote: Counting objects: 100% (2106/2106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (388/388), done.\u001b[K\n",
            "remote: Total 5825 (delta 1785), reused 1865 (delta 1705), pack-reused 3719\u001b[K\n",
            "Receiving objects: 100% (5825/5825), 13.44 MiB | 27.24 MiB/s, done.\n",
            "Resolving deltas: 100% (3106/3106), done.\n",
            "Cloning into '/content/stable-diffusion-webui/extensions/openpose-editor'...\n",
            "remote: Enumerating objects: 385, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 385 (delta 80), reused 63 (delta 57), pack-reused 280\u001b[K\n",
            "Receiving objects: 100% (385/385), 1.14 MiB | 8.87 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "Cloning into '/content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 143 (delta 25), reused 21 (delta 21), pack-reused 109\u001b[K\n",
            "Receiving objects: 100% (143/143), 37.92 KiB | 3.16 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Cloning into '/content/stable-diffusion-webui/extensions/a1111-sd-webui-tagcomplete'...\n",
            "remote: Enumerating objects: 1138, done.\u001b[K\n",
            "remote: Counting objects: 100% (1138/1138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (453/453), done.\u001b[K\n",
            "remote: Total 1138 (delta 642), reused 1081 (delta 624), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1138/1138), 3.82 MiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (642/642), done.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1109  100  1109    0     0  10174      0 --:--:-- --:--:-- --:--:-- 10174\n",
            "100 2034M  100 2034M    0     0  57.0M      0  0:00:35  0:00:35 --:--:-- 59.7M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1117  100  1117    0     0  11397      0 --:--:-- --:--:-- --:--:-- 11397\n",
            "100  784M  100  784M    0     0   214M      0  0:00:03  0:00:03 --:--:--  232M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1155  100  1155    0     0  15197      0 --:--:-- --:--:-- --:--:-- 15197\n",
            "100  689M  100  689M    0     0   221M      0  0:00:03  0:00:03 --:--:--  227M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1153  100  1153    0     0  12670      0 --:--:-- --:--:-- --:--:-- 12670\n",
            "100  689M  100  689M    0     0   206M      0  0:00:03  0:00:03 --:--:--  213M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1151  100  1151    0     0  14948      0 --:--:-- --:--:-- --:--:-- 14948\n",
            "100  689M  100  689M    0     0   211M      0  0:00:03  0:00:03 --:--:--  226M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1151  100  1151    0     0  15554      0 --:--:-- --:--:-- --:--:-- 15554\n",
            "100  689M  100  689M    0     0   225M      0  0:00:03  0:00:03 --:--:--  237M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1161  100  1161    0     0  16585      0 --:--:-- --:--:-- --:--:-- 16826\n",
            "100  689M  100  689M    0     0   226M      0  0:00:03  0:00:03 --:--:--  239M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1163  100  1163    0     0  15931      0 --:--:-- --:--:-- --:--:-- 15931\n",
            "100  689M  100  689M    0     0   230M      0  0:00:02  0:00:02 --:--:--  243M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1161  100  1161    0     0  14884      0 --:--:-- --:--:-- --:--:-- 15077\n",
            "100  689M  100  689M    0     0   202M      0  0:00:03  0:00:03 --:--:--  216M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1149  100  1149    0     0  15527      0 --:--:-- --:--:-- --:--:-- 15527\n",
            "100  689M  100  689M    0     0   221M      0  0:00:03  0:00:03 --:--:--  236M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 38657  100 38657    0     0   174k      0 --:--:-- --:--:-- --:--:--  174k\n",
            "/content/stable-diffusion-webui\n",
            "D\tembeddings/Place Textual Inversion embeddings here.txt\n",
            "Note: switching to '3715ece'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 3715ece0 Merge pull request #7717 from zijiren233/master\n",
            "Cloning into 'embeddings'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 44 (delta 7), reused 1 (delta 0), pack-reused 22\u001b[K\n",
            "Unpacking objects: 100% (44/44), 5.98 KiB | 680.00 KiB/s, done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=c1cc89e415a9c32f7ad9fb3c36cb60e6b3b3240a56708a1baaa143e3b6ef0822\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/af/d0/7a12f82cab69f65d51107f48bcd6179e29b9a69a90546332b3\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-8.6.0-cp310-none-manylinux_2_17_x86_64.whl (819.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.0.131-py3-none-manylinux1_x86_64.whl (719.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.6/719.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, tensorrt, nvidia-tensorrt\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.0.131 nvidia-tensorrt-99.0.0 tensorrt-8.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade fastapi==0.90.1\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "!git clone https://github.com/Mikubill/sd-webui-controlnet /content/stable-diffusion-webui/extensions/sd-webui-controlnet\n",
        "!git clone https://github.com/fkunn1326/openpose-editor /content/stable-diffusion-webui/extensions/openpose-editor\n",
        "!git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser /content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser\n",
        "!git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete /content/stable-diffusion-webui/extensions/a1111-sd-webui-tagcomplete\n",
        "\n",
        "# Model(s) setup\n",
        "# Below are model codes for our base model, just pick 1 or 2 to avoid colab crashing out of memory\n",
        "# Our desired model is not in the list? we could always change it ourselves (how-to: https://youtu.be/vj-QrS_mWQI or https://youtu.be/MwyfwPFezvY)\n",
        "# Remove the '#' from the beginning of '!curl' and '!mv' line(s) of our choosen model(s)\n",
        "\n",
        "# STABLE DIFFUSION 1.5\n",
        "#!curl -Lo sd1.5.ckpt https://huggingface.co/nolanaatama/sd15/resolve/main/model.ckpt\n",
        "#!curl -Lo sd1.5.yaml https://huggingface.co/nolanaatama/sd15/raw/main/model.yaml\n",
        "#!mv \"/content/sd1.5.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "#!mv \"/content/sd1.5.yaml\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# REALISTIC VISION\n",
        "#!curl -Lo realisticvisionv1.3.ckpt https://huggingface.co/nolanaatama/rv13/resolve/main/rv13.ckpt\n",
        "#!mv \"/content/realisticvisionv1.3.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# CHILLOUTMIX\n",
        "#!curl -Lo chilloutmixni.safetensors https://huggingface.co/nolanaatama/chomni/resolve/main/chomni.safetensors\n",
        "#!mv \"/content/chilloutmixni.safetensors\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# DREAMSHAPER\n",
        "#!curl -Lo dreamshaper3.32bvcf.ckpt https://huggingface.co/Lykon/DreamShaper/resolve/main/Dreamshaper_3.32_baked_vae_clip_fix.ckpt\n",
        "#!mv \"/content/dreamshaper3.32bvcf.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# DELIBERATE\n",
        "#!curl -Lo deliberate.ckpt https://huggingface.co/nolanaatama/dlbrt/resolve/main/deliberate.ckpt\n",
        "#!mv \"/content/deliberate.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# ANYTHING V3\n",
        "!curl -Lo anythingv3.ckpt https://huggingface.co/nolanaatama/av3/resolve/main/av3.ckpt\n",
        "!curl -Lo anythingv3.vae.pt https://huggingface.co/nolanaatama/av3/resolve/main/av3.vae.pt\n",
        "!mv \"/content/anythingv3.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "!mv \"/content/anythingv3.vae.pt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# ANYTHING V4.5\n",
        "#!curl -Lo anythingv4.5.ckpt https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt\n",
        "#!curl -Lo anythingv4.5.vae.pt https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.0.vae.pt\n",
        "#!mv \"/content/anythingv4.5.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "#!mv \"/content/anythingv4.5.vae.pt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# ABYSSORANGEMIX2\n",
        "#!curl -Lo abyssorangemix2.safetensors https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors\n",
        "#!curl -Lo abyssorangemix2.vae.pt https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt\n",
        "#!mv \"/content/abyssorangemix2.safetensors\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "#!mv \"/content/abyssorangemix2.vae.pt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# PASTEL-MIX\n",
        "#!curl -Lo pastelmix.ckpt https://huggingface.co/andite/pastel-mix/resolve/main/pastelmix-better-vae-fp32.ckpt\n",
        "#!mv \"/content/pastelmix.ckpt\" \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "\n",
        "# ControlNet\n",
        "# canny\n",
        "!curl -Lo control_canny-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_canny-fp16.safetensors\n",
        "!mv \"/content/control_canny-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# depth\n",
        "!curl -Lo control_depth-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors\n",
        "!mv \"/content/control_depth-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# hed\n",
        "!curl -Lo control_hed-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_hed-fp16.safetensors\n",
        "!mv \"/content/control_hed-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# mlsd\n",
        "!curl -Lo control_mlsd-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_mlsd-fp16.safetensors\n",
        "!mv \"/content/control_mlsd-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# normal\n",
        "!curl -Lo control_normal-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors\n",
        "!mv \"/content/control_normal-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# openpose\n",
        "!curl -Lo control_openpose-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors\n",
        "!mv \"/content/control_openpose-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# scribble\n",
        "!curl -Lo control_scribble-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors\n",
        "!mv \"/content/control_scribble-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# seg\n",
        "!curl -Lo control_seg-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_seg-fp16.safetensors\n",
        "!mv \"/content/control_seg-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "# style\n",
        "!curl -Lo t2iadapter_style-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/blob/main/t2iadapter_style-fp16.safetensors\n",
        "!mv \"/content/t2iadapter_style-fp16.safetensors\" \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "shutil.rmtree('/content/stable-diffusion-webui/embeddings')\n",
        "%cd /content/stable-diffusion-webui\n",
        "!git checkout 3715ece\n",
        "!git clone https://huggingface.co/nolanaatama/embeddings\n",
        "# !pip install --upgrade --force-reinstall torchvision\n",
        "# !pip install -U xformers\n",
        "!pip install nvidia-pyindex\n",
        "!pip install nvidia-tensorrt\n",
        "os.environ['XFORMERS_MORE_DETAILS'] = '1'\n",
        "# !COMMANDLINE_ARGS=\"--share --disable-safe-unpickle --no-half-vae --xformers --reinstall-xformers --enable-insecure-extension-access\" REQS_FILE=\"requirements.txt\" python launch.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBVa1N2RNqD2",
        "outputId": "20311834-7f45-41ce-ac6e-b3971e91ec0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
            "  Using cached Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.0\n",
            "  Using cached torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmake\n",
            "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.1.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.1-py3-none-any.whl size=88188 sha256=0045736c67e777d0cd69d091869d93c5094f22303faa8f81d18792e0b20db1c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/35/e6/2ba4f52d2763592eb8474f60e192f06e3d57be198526ef1048\n",
            "Successfully built lit\n",
            "Installing collected packages: mpmath, lit, cmake, wheel, urllib3, typing-extensions, sympy, setuptools, pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: lit\n",
            "    Found existing installation: lit 16.0.1\n",
            "    Uninstalling lit-16.0.1:\n",
            "      Successfully uninstalled lit-16.0.1\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.25.2\n",
            "    Uninstalling cmake-3.25.2:\n",
            "      Successfully uninstalled cmake-3.25.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.40.0\n",
            "    Uninstalling wheel-0.40.0:\n",
            "      Successfully uninstalled wheel-0.40.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.11.1\n",
            "    Uninstalling sympy-1.11.1:\n",
            "      Successfully uninstalled sympy-1.11.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.6.1\n",
            "    Uninstalling setuptools-67.6.1:\n",
            "      Successfully uninstalled setuptools-67.6.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.5.0\n",
            "    Uninstalling Pillow-9.5.0:\n",
            "      Successfully uninstalled Pillow-9.5.0\n",
            "  Attempting uninstall: nvidia-nccl-cu11\n",
            "    Found existing installation: nvidia-nccl-cu11 2.14.3\n",
            "    Uninstalling nvidia-nccl-cu11-2.14.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu11-2.14.3\n",
            "  Attempting uninstall: nvidia-cufft-cu11\n",
            "    Found existing installation: nvidia-cufft-cu11 10.9.0.58\n",
            "    Uninstalling nvidia-cufft-cu11-10.9.0.58:\n",
            "      Successfully uninstalled nvidia-cufft-cu11-10.9.0.58\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.7.99\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.2\n",
            "    Uninstalling MarkupSafe-2.1.2:\n",
            "      Successfully uninstalled MarkupSafe-2.1.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.11.0\n",
            "    Uninstalling filelock-3.11.0:\n",
            "      Successfully uninstalled filelock-3.11.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu11\n",
            "    Found existing installation: nvidia-nvtx-cu11 11.7.91\n",
            "    Uninstalling nvidia-nvtx-cu11-11.7.91:\n",
            "      Successfully uninstalled nvidia-nvtx-cu11-11.7.91\n",
            "  Attempting uninstall: nvidia-cusparse-cu11\n",
            "    Found existing installation: nvidia-cusparse-cu11 11.7.4.91\n",
            "    Uninstalling nvidia-cusparse-cu11-11.7.4.91:\n",
            "      Successfully uninstalled nvidia-cusparse-cu11-11.7.4.91\n",
            "  Attempting uninstall: nvidia-curand-cu11\n",
            "    Found existing installation: nvidia-curand-cu11 10.2.10.91\n",
            "    Uninstalling nvidia-curand-cu11-10.2.10.91:\n",
            "      Successfully uninstalled nvidia-curand-cu11-10.2.10.91\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.7.99\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "    Found existing installation: nvidia-cuda-cupti-cu11 11.7.101\n",
            "    Uninstalling nvidia-cuda-cupti-cu11-11.7.101:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.7.101\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.10.3.66\n",
            "    Uninstalling nvidia-cublas-cu11-11.10.3.66:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu11\n",
            "    Found existing installation: nvidia-cusolver-cu11 11.4.0.1\n",
            "    Uninstalling nvidia-cusolver-cu11-11.4.0.1:\n",
            "      Successfully uninstalled nvidia-cusolver-cu11-11.4.0.1\n",
            "  Attempting uninstall: nvidia-cudnn-cu11\n",
            "    Found existing installation: nvidia-cudnn-cu11 8.5.0.96\n",
            "    Uninstalling nvidia-cudnn-cu11-8.5.0.96:\n",
            "      Successfully uninstalled nvidia-cudnn-cu11-8.5.0.96\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0\n",
            "    Uninstalling torch-2.0.0:\n",
            "      Successfully uninstalled torch-2.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "xformers 0.0.16rc425 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "open-clip-torch 2.7.0 requires protobuf==3.20.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 certifi-2022.12.7 charset-normalizer-3.1.0 cmake-3.26.3 filelock-3.11.0 idna-3.4 jinja2-3.1.2 lit-16.0.1 mpmath-1.3.0 networkx-3.1 numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pillow-9.5.0 requests-2.28.2 setuptools-67.6.1 sympy-1.11.1 torch-2.0.0 torchvision-0.15.1 triton-2.0.0 typing-extensions-4.5.0 urllib3-1.26.15 wheel-0.40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m xformers.info output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkRsY3IHNzZV",
        "outputId": "38a42c91-15f5-4e0c-bc84-27b47133304e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 1.13.1+cu117 with CUDA 1107 (you have 2.0.0+cu117)\n",
            "    Python  3.9.16 (you have 3.9.16)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xformers/_cpp_lib.py\", line 117, in _register_extensions\n",
            "    torch.ops.load_library(ext_specs.origin)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_ops.py\", line 643, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.9/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xformers/_cpp_lib.py\", line 127, in <module>\n",
            "    _build_metadata = _register_extensions()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xformers/_cpp_lib.py\", line 119, in _register_extensions\n",
            "    raise xFormersInvalidLibException(build_metadata) from exc\n",
            "xformers._cpp_lib.xFormersInvalidLibException: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 1.13.1+cu117 with CUDA 1107 (you have 2.0.0+cu117)\n",
            "    Python  3.9.16 (you have 3.9.16)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "xFormers 0.0.16rc425\n",
            "memory_efficient_attention.cutlassF:               unavailable\n",
            "memory_efficient_attention.cutlassB:               unavailable\n",
            "memory_efficient_attention.flshattF:               unavailable\n",
            "memory_efficient_attention.flshattB:               unavailable\n",
            "memory_efficient_attention.smallkF:                unavailable\n",
            "memory_efficient_attention.smallkB:                unavailable\n",
            "memory_efficient_attention.tritonflashattF:        available\n",
            "memory_efficient_attention.tritonflashattB:        available\n",
            "swiglu.fused.p.cpp:                                not built\n",
            "is_triton_available:                               True\n",
            "is_functorch_available:                            False\n",
            "pytorch.version:                                   2.0.0+cu117\n",
            "pytorch.cuda:                                      available\n",
            "gpu.compute_capability:                            7.5\n",
            "gpu.name:                                          Tesla T4\n",
            "build.info:                                        available\n",
            "build.cuda_version:                                1107\n",
            "build.python_version:                              3.9.16\n",
            "build.torch_version:                               1.13.1+cu117\n",
            "build.env.TORCH_CUDA_ARCH_LIST:                    5.0+PTX 6.0 6.1 7.0 7.5 8.0 8.6\n",
            "build.env.XFORMERS_BUILD_TYPE:                     Release\n",
            "build.env.XFORMERS_ENABLE_DEBUG_ASSERTIONS:        None\n",
            "build.env.NVCC_FLAGS:                              None\n",
            "build.env.XFORMERS_PACKAGE_FROM:                   wheel-v0.0.16rc425\n",
            "source.privacy:                                    open source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!COMMANDLINE_ARGS=\"--share --disable-safe-unpickle --no-half-vae --xformers --reinstall-xformers --enable-insecure-extension-access\" REQS_FILE=\"requirements.txt\" python launch.py"
      ],
      "metadata": {
        "id": "qmcT_PQddcf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a50ed29-f691-4988-946e-82e1cbc17504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
            "Commit hash: 3715ece0adce7bf7c5e9c5ab3710b2fdc3848f39\n",
            "Installing gfpgan\n",
            "Installing clip\n",
            "Installing open_clip\n",
            "Installing xformers\n",
            "Cloning Stable Diffusion into repositories/stable-diffusion-stability-ai...\n",
            "Cloning Taming Transformers into repositories/taming-transformers...\n",
            "Cloning K-diffusion into repositories/k-diffusion...\n",
            "Cloning CodeFormer into repositories/CodeFormer...\n",
            "Cloning BLIP into repositories/BLIP...\n",
            "Installing requirements for CodeFormer\n",
            "Installing requirements for Web UI\n",
            "Installing sd-webui-controlnet requirement: mediapipe\n",
            "Installing sd-webui-controlnet requirement: svglib\n",
            "Installing sd-webui-controlnet requirement: fvcore\n",
            "\n",
            "Launching Web UI with arguments: --share --disable-safe-unpickle --no-half-vae --xformers --enable-insecure-extension-access\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/launch.py\", line 361, in <module>\n",
            "    start()\n",
            "  File \"/content/stable-diffusion-webui/launch.py\", line 352, in start\n",
            "    import webui\n",
            "  File \"/content/stable-diffusion-webui/webui.py\", line 15, in <module>\n",
            "    from modules import import_hook, errors, extra_networks, ui_extra_networks_checkpoints\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks_checkpoints.py\", line 6, in <module>\n",
            "    from modules import shared, ui_extra_networks, sd_models\n",
            "  File \"/content/stable-diffusion-webui/modules/shared.py\", line 12, in <module>\n",
            "    import modules.interrogate\n",
            "  File \"/content/stable-diffusion-webui/modules/interrogate.py\", line 11, in <module>\n",
            "    from torchvision import transforms\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/__init__.py\", line 1, in <module>\n",
            "    from ._optical_flow import FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/_optical_flow.py\", line 12, in <module>\n",
            "    from ..io.image import _read_png_16\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/io/__init__.py\", line 8, in <module>\n",
            "    from ._load_gpu_decoder import _HAS_GPU_VIDEO_DECODER\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/io/_load_gpu_decoder.py\", line 1, in <module>\n",
            "    from ..extension import _load_library\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/extension.py\", line 107, in <module>\n",
            "    _check_cuda_version()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/extension.py\", line 80, in _check_cuda_version\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Detected that PyTorch and torchvision were compiled with different CUDA versions. PyTorch has CUDA Version=11.7 and torchvision has CUDA Version=11.8. Please reinstall the torchvision that matches your PyTorch install.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (OPTIONAL) LoRAs"
      ],
      "metadata": {
        "id": "0DwYF_aLUXKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. After the gradio link show up, stop the first cell & clear the code output👆"
      ],
      "metadata": {
        "id": "JUtPlg328avv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Load the LoRA & launch the web ui"
      ],
      "metadata": {
        "id": "xy_WyDzNUgd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the LoRA code from other LoRA setup (download the setup file after editing the LoRA code cell to avoid repeat input for next session)\n",
        "# How-to download the setup file: Click 'File' menu -> 'Download' -> 'Download .ipynb'\n",
        "# Load LoRA from Google Drive: https://youtu.be/G1QZfAPUMaM\n",
        "\n",
        "# LoRA 1\n",
        "#!curl ...\n",
        "#!mv ...\n",
        "\n",
        "# LoRA 2\n",
        "#!curl ...\n",
        "#!mv ...\n",
        "\n",
        "# LoRA 3\n",
        "#!curl ...\n",
        "#!mv ...\n",
        "\n",
        "# ...\n",
        "\n",
        "!COMMANDLINE_ARGS=\"--share --disable-safe-unpickle --no-half-vae --xformers --reinstall-xformers --enable-insecure-extension-access\" REQS_FILE=\"requirements.txt\" python launch.py"
      ],
      "metadata": {
        "id": "3EOPSiOgUs4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhwIXzcgfkoR"
      },
      "source": [
        "# 📚 GitHub for more: [_@nolanaatama_](https://github.com/nolanaatama)\n",
        "# 📦 Repo: [Github](https://github.com/nolanaatama/sd-1click-colab)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}