{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixd-ai-hub/Research-Ground/blob/project%2FCU-865d7n3wb-nft-generation/Stable_Diffusion_Application1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import seed\n",
        "\n",
        "class Manager:\n",
        "  def __init__(self):\n",
        "    # self.pipeline_assigner = {}\n",
        "    pass\n",
        "\n",
        "  class Diffusion:\n",
        "\n",
        "    def get_settings():\n",
        "      pass\n",
        "\n",
        "    def set_settings():\n",
        "      pass\n",
        "\n",
        "    def patch_nsfw():\n",
        "      import shutil\n",
        "      import os\n",
        "      os.remove('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py')\n",
        "      if ENABLE_NSFW_FILTER:\n",
        "        shutil.copyfile(f'/content/safety_checker.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py')\n",
        "      else:\n",
        "        shutil.copyfile(f'/content/safety_checker_patched.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py')\n",
        "\n",
        "    def make_pipe():\n",
        "      pass\n",
        "\n",
        "    def cache_pipe():\n",
        "      pass\n",
        "\n",
        "    def clear_pipe():\n",
        "      pass\n",
        "\n",
        "    class Upscaler:\n",
        "      pass\n",
        "\n",
        "    class Scheduler:\n",
        "      pass\n",
        "\n",
        "    class Methods:\n",
        "      class Prompt:\n",
        "        pass\n",
        "\n",
        "      class ImgToImg:\n",
        "        pass\n",
        "\n",
        "      class Inpaintin:\n",
        "        pass\n",
        "\n",
        "\n",
        "class Colab:\n",
        "  def clean_env():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  class Images:\n",
        "    def resize_image():\n",
        "      pass\n",
        "\n",
        "    def suggest_resolution():\n",
        "      pass\n",
        "\n",
        "  class Library:\n",
        "    def get_imports(requesting_library):\n",
        "      pass\n",
        "\n",
        "  class Downloader:\n",
        "    def fetch_bytes(url_or_path):\n",
        "      if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "          from urllib.request import urlopen\n",
        "          return urlopen(url_or_path)\n",
        "      return open(url_or_path, 'r')\n",
        "\n",
        "\n",
        "global LAST_INIT\n",
        "global LAST_VRAM\n",
        "global LAST_MODE\n",
        "global LAST_MODEL_ID\n",
        "global LAST_ENABLE_NSFW_FILTER\n",
        "global LAST_DIFFUSERS_VERSION\n",
        "global INIT_IMAGE\n",
        "global INPAINT_IMAGE\n",
        "global MASK_IMAGE\n",
        "\n",
        "def clean_env():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def fetch_bytes(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        from urllib.request import urlopen\n",
        "        return urlopen(url_or_path)\n",
        "    return open(url_or_path, 'r')\n",
        "\n",
        "\n",
        "def patch_nsfw():\n",
        "  import shutil\n",
        "  import os\n",
        "  os.remove('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py')\n",
        "  if ENABLE_NSFW_FILTER:\n",
        "    shutil.copyfile(f'/content/safety_checker.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py')\n",
        "  else:\n",
        "    shutil.copyfile(f'/content/safety_checker_patched.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py')\n",
        "\n",
        "\n",
        "def forward(self, x, context=None, mask=None):\n",
        "\n",
        "    import math\n",
        "    from torch import einsum\n",
        "    try:\n",
        "      from einops import rearrange\n",
        "    except ModuleNotFoundError:\n",
        "      !pip install einops\n",
        "      from einops import rearrange\n",
        "    import types\n",
        "    from diffusers.models.attention import CrossAttention\n",
        "    import torch\n",
        "    batch_size, sequence_length, dim = x.shape\n",
        "\n",
        "    h = self.heads\n",
        "\n",
        "    q = self.to_q(x)\n",
        "    context = context if context is not None else x\n",
        "    k = self.to_k(context)\n",
        "    v = self.to_v(context)\n",
        "    del context, x\n",
        "\n",
        "    q = self.reshape_heads_to_batch_dim(q)\n",
        "    k = self.reshape_heads_to_batch_dim(k)\n",
        "    v = self.reshape_heads_to_batch_dim(v)\n",
        "\n",
        "    r1 = torch.zeros(q.shape[0], q.shape[1], v.shape[2], device=q.device)\n",
        "\n",
        "    stats = torch.cuda.memory_stats(q.device)\n",
        "    mem_total = torch.cuda.get_device_properties(0).total_memory\n",
        "    mem_active = stats['active_bytes.all.current']\n",
        "    mem_free = mem_total - mem_active\n",
        "\n",
        "    mem_required = q.shape[0] * q.shape[1] * k.shape[1] * 4 * 2.5\n",
        "    steps = 1\n",
        "\n",
        "    if mem_required > mem_free:\n",
        "        steps = 2**(math.ceil(math.log(mem_required / mem_free, 2)))\n",
        "\n",
        "    slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n",
        "    for i in range(0, q.shape[1], slice_size):\n",
        "        end = i + slice_size\n",
        "        s1 = einsum('b i d, b j d -> b i j', q[:, i:end], k)\n",
        "        s1 *= self.scale\n",
        "\n",
        "        s2 = s1.softmax(dim=-1)\n",
        "        del s1\n",
        "\n",
        "        r1[:, i:end] = einsum('b i j, b j d -> b i d', s2, v)\n",
        "        del s2\n",
        "\n",
        "    del q, k, v\n",
        "\n",
        "    r2 = rearrange(r1, '(b h) n d -> b n (h d)', h=h)\n",
        "    del r1\n",
        "\n",
        "    return self.to_out(r2)\n",
        "\n",
        "def optimize_attention(model):\n",
        "    import types\n",
        "    from diffusers.models.attention import CrossAttention\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, CrossAttention):\n",
        "            module.forward = types.MethodType(forward, module)\n",
        "\n",
        "\n",
        "def make_pipe():\n",
        "  # TODO: Cache pipes and clean this. Very messy right now\n",
        "  global LOW_VRAM_PATCH\n",
        "  global pipe\n",
        "  pipe = None\n",
        "  clean_env()\n",
        "  if MODE == \"IMG2IMG\":\n",
        "    if LOW_VRAM_PATCH:\n",
        "      try:\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "      except Exception:\n",
        "        !pip install transformers\n",
        "        # try:\n",
        "        #   with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "        #     key = f.read().decode('utf-8').split(':')\n",
        "        # except OSError as e:\n",
        "        #   print(e)\n",
        "        huggingface_username = 'x90'\n",
        "        huggingface_token = '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'\n",
        "        !echo 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 | huggingface-cli login\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "    else:\n",
        "      try:\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, use_auth_token=True).to(\"cuda\")\n",
        "      except Exception:\n",
        "        !pip install transformers\n",
        "        # try:\n",
        "        #   with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "        #     key = f.read().decode('utf-8').split(':')\n",
        "        # except OSError as e:\n",
        "        #   print(e)\n",
        "        huggingface_username = 'x90'\n",
        "        huggingface_token = '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'\n",
        "        !echo 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 | huggingface-cli login\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, use_auth_token=True).to(\"cuda\")\n",
        "  elif MODE == \"Inpainting\":\n",
        "    if LOW_VRAM_PATCH:\n",
        "      try:\n",
        "        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "      except Exception:\n",
        "        !pip install transformers\n",
        "        # try:\n",
        "        #   with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "        #     key = f.read().decode('utf-8').split(':')\n",
        "        # except OSError as e:\n",
        "        #   print(e)\n",
        "        huggingface_username = 'x90'\n",
        "        huggingface_token = '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'\n",
        "        !echo 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 | huggingface-cli login\n",
        "        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "    else:\n",
        "      try:\n",
        "        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, use_auth_token=True).to(\"cuda\")\n",
        "      except Exception:\n",
        "        !pip install transformers\n",
        "        # try:\n",
        "        #   with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "        #     key = f.read().decode('utf-8').split(':')\n",
        "        # except OSError as e:\n",
        "        #   print(e)\n",
        "        huggingface_username = 'x90'\n",
        "        huggingface_token = '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'\n",
        "        !echo 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 | huggingface-cli login\n",
        "        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, use_auth_token=True).to(\"cuda\")\n",
        "  elif LOW_VRAM_PATCH:\n",
        "      try:\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "      except Exception:\n",
        "        !pip install transformers\n",
        "        # try:\n",
        "        #   with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "        #     key = f.read().decode('utf-8').split(':')\n",
        "        # except OSError as e:\n",
        "        #   print(e)\n",
        "        huggingface_username = 'x90'\n",
        "        huggingface_token = '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'\n",
        "        !echo $huggingface_token | huggingface-cli login\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "        del pipe.vae.encoder\n",
        "  else:\n",
        "    try:\n",
        "      pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True).to(\"cuda\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      !pip install transformers\n",
        "      try:\n",
        "        with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "          key = f.read().decode('utf-8').split(':')\n",
        "      except OSError as e:\n",
        "        print(e)\n",
        "      huggingface_username = 'x90'\n",
        "      huggingface_token = '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'\n",
        "      !echo $huggingface_token | huggingface-cli login\n",
        "      pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True).to(\"cuda\")\n",
        "      del pipe.vae.encoder\n",
        "  if VRAM_OVER_SPEED:\n",
        "    print(\"Creating pipe optimizations\")\n",
        "    pipe.enable_attention_slicing()\n",
        "    optimize_attention(pipe.unet)\n",
        "\n",
        "def make_scheduler():\n",
        "  if SCHEDULER == 'default':\n",
        "    pipe.scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, skip_prk_steps=True)\n",
        "  elif SCHEDULER == 'pndm':\n",
        "    pipe.scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, skip_prk_steps=True)\n",
        "  elif SCHEDULER == 'k-lms':\n",
        "    pipe.scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "  elif SCHEDULER == 'ddim':\n",
        "    pipe.scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "\n",
        "\n",
        "def make_image():\n",
        "  # Clean this\n",
        "  gen_seed = torch.Generator(\"cuda\").manual_seed(SEED)\n",
        "  global pipe\n",
        "  global INIT_IMAGE\n",
        "  global INPAINT_IMAGE\n",
        "  global MASK_IMAGE\n",
        "  if MODE == \"Inpainting\":\n",
        "    print(\"Inpainting Mode\")\n",
        "    print(\"Init Image (automatically resized to match user input)\")\n",
        "    INPAINT_IMAGE = INPAINT_IMAGE.resize((WIDTH, HEIGHT))\n",
        "    MASK_IMAGE = MASK_IMAGE.resize((WIDTH, HEIGHT))\n",
        "    display(INPAINT_IMAGE)\n",
        "    display(MASK_IMAGE)\n",
        "\n",
        "    inpaint_image = INPAINT_IMAGE\n",
        "    mask_image = MASK_IMAGE\n",
        "    # init_image = INIT_IMAGE.convert(\"RGB\"))\n",
        "    #\n",
        "    if SCHEDULER == 'ddim':\n",
        "      try:\n",
        "        image = pipe(PROMPT, init_image=inpaint_image, mask_image=mask_image, strength=INPAINT_STRENGTH, guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)[\"sample\"][0]\n",
        "      except IndexError:\n",
        "        try:\n",
        "          image = pipe(PROMPT, init_image=inpaint_image, mask_image=mask_image, strength=INPAINT_STRENGTH, guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)[\"sample\"][0]\n",
        "        except UnboundLocalError or NameError:\n",
        "          make_pipe()\n",
        "          make_scheduler()\n",
        "          make_image()\n",
        "    else:\n",
        "      try:\n",
        "        image = pipe(PROMPT, init_image=inpaint_image, mask_image=mask_image, strength=INPAINT_STRENGTH, guidance_scale=SCALE, generator=gen_seed)[\"sample\"][0]\n",
        "      except IndexError:\n",
        "        try:\n",
        "          image = pipe(PROMPT, init_image=inpaint_image, mask_image=mask_image, strength=INPAINT_STRENGTH, guidance_scale=SCALE, generator=gen_seed)[\"sample\"][0]\n",
        "        except UnboundLocalError or NameError:\n",
        "          make_pipe()\n",
        "          make_scheduler()\n",
        "          make_image()\n",
        "      except UnboundLocalError or NameError:\n",
        "        make_pipe()\n",
        "        make_scheduler()\n",
        "        make_image\n",
        "      except RuntimeError as e:\n",
        "        print(e)\n",
        "        clean_env()\n",
        "        try:\n",
        "          image = None\n",
        "        except Exception:\n",
        "          pass\n",
        "        raise SystemExit('\\33[33mUsing too much VRAM, lower your settings.\\33[0m')\n",
        "  elif MODE == \"IMG2IMG\":\n",
        "    print(\"Init Mode\")\n",
        "    print(\"Init Image (automatically resized to match user input)\")\n",
        "    INIT_IMAGE = INIT_IMAGE.resize((WIDTH, HEIGHT))\n",
        "    display(INIT_IMAGE)\n",
        "    def preprocess(image):\n",
        "      w, h = image.size\n",
        "      w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "      image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "      image = np.array(image).astype(np.float32) / 255.0\n",
        "      image = image[None].transpose(0, 3, 1, 2)\n",
        "      image = torch.from_numpy(image)\n",
        "      return 2.*image - 1.\n",
        "\n",
        "    init_image = preprocess(INIT_IMAGE.convert(\"RGB\"))\n",
        "    # init_image = INIT_IMAGE.convert(\"RGB\"))\n",
        "    if SCHEDULER == 'ddim':\n",
        "      try:\n",
        "        image = pipe(PROMPT, num_inference_steps=STEPS, init_image=init_image, strength=INIT_STRENGTH, guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)[\"sample\"][0]\n",
        "      except IndexError:\n",
        "        try:\n",
        "          image = pipe(PROMPT, num_inference_steps=STEPS, init_image=init_image, strength=INIT_STRENGTH, guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)[\"sample\"][0]\n",
        "        except UnboundLocalError or NameError:\n",
        "          make_pipe()\n",
        "          make_scheduler()\n",
        "          make_image()\n",
        "    else:\n",
        "      try:\n",
        "        image = pipe(prompt=PROMPT, num_inference_steps=STEPS, init_image=init_image, strength=INIT_STRENGTH, guidance_scale=SCALE, generator=gen_seed)[\"sample\"][0]\n",
        "      except IndexError:\n",
        "        try:\n",
        "          image = pipe(prompt=PROMPT, num_inference_steps=STEPS, init_image=init_image, strength=INIT_STRENGTH, guidance_scale=SCALE, generator=gen_seed)[\"sample\"][0]\n",
        "        except UnboundLocalError or NameError:\n",
        "          make_pipe()\n",
        "          make_scheduler()\n",
        "          make_image()\n",
        "      except UnboundLocalError or NameError:\n",
        "        make_pipe()\n",
        "        make_scheduler()\n",
        "        make_image\n",
        "      except RuntimeError as e:\n",
        "        print(e)\n",
        "        clean_env()\n",
        "        try:\n",
        "          image = None\n",
        "        except Exception:\n",
        "          pass\n",
        "        raise SystemExit('\\33[33mUsing too much VRAM, lower your settings.\\33[0m')\n",
        "  else:\n",
        "    if SCHEDULER == 'ddim':\n",
        "      try:\n",
        "        image = pipe(PROMPT, num_inference_steps=STEPS, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)[\"sample\"][0]\n",
        "      except IndexError:\n",
        "        try:\n",
        "          image = pipe(PROMPT, num_inference_steps=STEPS-1, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)[\"sample\"][0]\n",
        "        except UnboundLocalError or NameError:\n",
        "          make_pipe()\n",
        "          make_scheduler()\n",
        "          make_image()\n",
        "    else:\n",
        "      try:\n",
        "        image = pipe(PROMPT, num_inference_steps=STEPS, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, generator=gen_seed)[\"sample\"][0]\n",
        "      except IndexError:\n",
        "        try:\n",
        "          image = pipe(PROMPT, num_inference_steps=STEPS-1, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, generator=gen_seed)[\"sample\"][0]\n",
        "        except UnboundLocalError or NameError:\n",
        "          make_pipe()\n",
        "          make_scheduler()\n",
        "          make_image()\n",
        "      except UnboundLocalError or NameError or TypeError:\n",
        "        make_pipe()\n",
        "        make_scheduler()\n",
        "        make_image\n",
        "      except RuntimeError as e:\n",
        "        print(e)\n",
        "        clean_env()\n",
        "        try:\n",
        "          image = None\n",
        "        except Exception:\n",
        "          pass\n",
        "        raise SystemExit('\\33[33mUsing too much VRAM, lower your settings.\\33[0m')\n",
        "  return image\n",
        "\n",
        "\n",
        "def diffusers_install():\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  try:\n",
        "    with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "      key = f.read().decode('utf-8').split(':')\n",
        "  except OSError as e:\n",
        "    print(e)\n",
        "\n",
        "  huggingface_username = 'x90'\n",
        "  huggingface_token = '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'\n",
        "  global LAST_INIT, LAST_VRAM, LAST_ENABLE_NSFW_FILTER, LAST_MODEL_ID, LAST_DIFFUSERS_VERSION\n",
        "  LAST_MODE = MODE\n",
        "  LAST_VRAM = LOW_VRAM_PATCH\n",
        "  LAST_ENABLE_NSFW_FILTER = ENABLE_NSFW_FILTER\n",
        "  LAST_MODEL_ID = MODEL_ID\n",
        "  LAST_DIFFUSERS_VERSION = DIFFUSERS_VERSION\n",
        "  try:\n",
        "    !git lfs install\n",
        "    !GIT_LFS_SKIP_SMUDGE=0\n",
        "    # This will take a while\n",
        "    !pip install transformers\n",
        "    !git lfs clone https://$huggingface_username:$huggingface_token@huggingface.co/CompVis/$MODEL_ID\n",
        "    if DIFFUSERS_VERSION == 'latest':\n",
        "      !pip install -U git+https://github.com/huggingface/diffusers.git\n",
        "    else:\n",
        "      !pip install -U git+https://github.com/huggingface/diffusers.git@$DIFFUSERS_VERSION\n",
        "\n",
        "    # Back up original NSFW file\n",
        "    !cp /usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py /content/safety_checker.py\n",
        "    !cp /content/safety_checker.py /content/safety_checker_patched.py\n",
        "    with open(f'/content/safety_checker_patched.py','r') as unpatched_file:\n",
        "      patch = unpatched_file.read().replace('for idx, has_nsfw_concept in enumerate(has_nsfw_concepts):','#for idx, has_nsfw_concept in enumerate(has_nsfw_concepts):').replace('if has_nsfw_concept:','# if has_nsfw_concept:').replace('images[idx] = np.zeros(images[idx].shape)  # black image', '# images[idx] = np.zeros(images[idx].shape)  # black image').replace(\"Potential NSFW content was detected in one or more images. A black image will be returned instead.\",\"Potential NSFW content was detected in one or more images. It's patched out, no actions were taken.\").replace(\" Try again with a different prompt and/or seed.\",\"\")\n",
        "    with open(f'/content/safety_checker_patched.py','w') as file:\n",
        "      file.write(patch)\n",
        "    patch_nsfw()\n",
        "\n",
        "    # make sure you're logged in with `huggingface-cli login`\n",
        "\n",
        "    !mkdir diffusers_output\n",
        "    !pip install pytorch-pretrained-bert\n",
        "    !pip install spacy ftfy\n",
        "    !python -m spacy download en\n",
        "    !pip install scipy\n",
        "    !echo $huggingface_token | huggingface-cli login\n",
        "  except OSError as e:\n",
        "    raise e\n",
        "  except BaseException as e:\n",
        "    raise e\n",
        "  finally:\n",
        "    if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "    print(\"Setup complete.\")\n",
        "    try:\n",
        "      from diffusers.schedulers import PNDMScheduler, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
        "      from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "    except ModuleNotFoundError or ImportError:\n",
        "      diffusers_install()\n",
        "      from diffusers.schedulers import PNDMScheduler, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
        "      from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "\n",
        "\n",
        "def GFPGAN_install():\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  if not os.path.exists('/content/GFPGAN'):\n",
        "    !git clone https://github.com/TencentARC/GFPGAN.git\n",
        "    %cd GFPGAN\n",
        "    !pip install basicsr\n",
        "    !pip install facexlib\n",
        "    !pip install -r requirements.txt\n",
        "    !python setup.py develop\n",
        "    !pip install realesrgan\n",
        "    !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n",
        "    %cd /content/\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "\n",
        "\n",
        "def ESRGAN_install():\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  if not os.path.exists('/content/Real-ESRGAN'):\n",
        "    !git clone https://github.com/sberbank-ai/Real-ESRGAN\n",
        "    !pip install -r Real-ESRGAN/requirements.txt\n",
        "    !wget https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x2.pth -O /content/Real-ESRGAN/weights/RealESRGAN_x2.pth\n",
        "    !wget https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x4.pth -O /content/Real-ESRGAN/weights/RealESRGAN_x4.pth\n",
        "    !wget https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x8.pth -O /content/Real-ESRGAN/weights/RealESRGAN_x8.pth\n",
        "  %cd Real-ESRGAN\n",
        "  from realesrgan import RealESRGAN\n",
        "  clear_output()\n",
        "  device = torch.device('cuda')\n",
        "  global UPSCALE_AMOUNT\n",
        "  if not os.path.exists(f'/content/Real-ESRGAN/weights/RealESRGAN_x{UPSCALE_AMOUNT}.pth'):\n",
        "    def closest_value(input_list, input_value):\n",
        "      difference = lambda input_list : abs(input_list - input_value)\n",
        "      res = min(input_list, key=difference)\n",
        "      return res\n",
        "    nearest_value = closest_value([2,4,8],UPSCALE_AMOUNT)\n",
        "    print(f'For Real-ESRGAN upscaling only 2, 4, and 8 are supported. Choosing the nearest Value: {nearest_value}')\n",
        "    UPSCALE_AMOUNT = nearest_value\n",
        "\n",
        "  model = RealESRGAN(device, scale = UPSCALE_AMOUNT)\n",
        "  model.load_weights(f'/content/Real-ESRGAN/weights/RealESRGAN_x{UPSCALE_AMOUNT}.pth')\n",
        "  %cd /content/\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "\n",
        "def CodeFormer_install():\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  if not os.path.exists('/content/CodeFormer'):\n",
        "    %cd /content\n",
        "    !git clone https://github.com/sczhou/CodeFormer.git\n",
        "    %cd CodeFormer\n",
        "    !pip install -r requirements.txt\n",
        "    !python basicsr/setup.py develop\n",
        "    !python scripts/download_pretrained_models.py facelib\n",
        "    !python scripts/download_pretrained_models.py CodeFormer\n",
        "    !mkdir temp\n",
        "    !mkdir results\n",
        "    %cd /content/\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "\n",
        "\n",
        "def populate():\n",
        "  global LAST_INIT\n",
        "  global LAST_MODE\n",
        "  global LAST_VRAM\n",
        "  global LAST_ENABLE_NSFW_FILTER\n",
        "  global LAST_MODEL_ID\n",
        "  global LAST_DIFFUSERS_VERSION\n",
        "  global pipe\n",
        "  pipe = None\n",
        "  clean_env()\n",
        "  if DIFFUSERS_VERSION != LAST_DIFFUSERS_VERSION:\n",
        "    !yes | pip uninstall diffusers\n",
        "  if LAST_MODEL_ID != MODEL_ID or DIFFUSERS_VERSION != LAST_DIFFUSERS_VERSION:\n",
        "    print(\"Setting up for new model..\")\n",
        "    diffusers_install()\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  print(\"Patching NSFW...\")\n",
        "  patch_nsfw()\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  print(\"Making Pipe...\")\n",
        "  make_pipe()\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  print(\"Injecting scheduler...\")\n",
        "  make_scheduler()\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  LAST_MODEL_ID = MODEL_ID\n",
        "  LAST_MODE = MODE\n",
        "  LAST_VRAM = LOW_VRAM_PATCH\n",
        "  LAST_ENABLE_NSFW_FILTER = ENABLE_NSFW_FILTER\n",
        "\n",
        "\n",
        "# Diffuse Function\n",
        "def upscale(image):\n",
        "    try:\n",
        "      from realesrgan import RealESRGAN\n",
        "    except ModuleNotFoundError:\n",
        "      if not os.path.exists('/content/Real-ESRGAN'):\n",
        "        ESRGAN_install()\n",
        "        %cd /content/Real-ESRGAN\n",
        "        from realesrgan import RealESRGAN\n",
        "        %cd /content\n",
        "    device = torch.device('cuda')\n",
        "    model = RealESRGAN(device, scale = UPSCALE_AMOUNT)\n",
        "    try:\n",
        "      model.load_weights(f'/content/Real-ESRGAN/weights/RealESRGAN_x{UPSCALE_AMOUNT}.pth')\n",
        "    except FileNotFoundError:\n",
        "      !wget https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x2.pth -O /content/Real-ESRGAN/weights/RealESRGAN_x2.pth\n",
        "      !wget https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x4.pth -O /content/Real-ESRGAN/weights/RealESRGAN_x4.pth\n",
        "      !wget https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x8.pth -O /content/Real-ESRGAN/weights/RealESRGAN_x8.pth\n",
        "      model.load_weights(f'/content/Real-ESRGAN/weights/RealESRGAN_x{UPSCALE_AMOUNT}.pth')\n",
        "    sr_image = model.predict(np.array(image))\n",
        "    return sr_image\n",
        "\n",
        "def diffuse_run():\n",
        "  # Can be cleaned quite a bit\n",
        "    global SEED\n",
        "    global pipe\n",
        "    if ORIG_SEED == 0:\n",
        "      if iteration is 0:\n",
        "        SEED = random.randint(0,sys.maxsize)\n",
        "      if iteration is not 0 and not KEEP_SEED:\n",
        "        SEED += 1\n",
        "    else:\n",
        "      if iteration > 0 and not KEEP_SEED:\n",
        "        SEED += 1\n",
        "    gen_seed = torch.Generator(\"cuda\").manual_seed(SEED)\n",
        "    epoch_time = int(time.time())\n",
        "    print(f'Seed: {SEED}, Scale: {SCALE}, Steps: {STEPS}')\n",
        "    clean_env()\n",
        "\n",
        "    try:\n",
        "      image = make_image()\n",
        "    except NameError or TypeError:\n",
        "      make_pipe()\n",
        "      make_scheduler()\n",
        "      image = make_image()\n",
        "    except RuntimeError as e:\n",
        "      print(e)\n",
        "      clean_env()\n",
        "      try:\n",
        "        image = None\n",
        "      except Exception:\n",
        "        pass\n",
        "      raise SystemExit('\\33[33mUsing too much VRAM, lower your settings.\\33[0m')\n",
        "    display(image)\n",
        "    filename = f'{str(epoch_time)}_scale_{SCALE}_steps_{STEPS}_seed_{SEED}.png'\n",
        "    filedir = f'{OUTDIR}/{filename}'\n",
        "    image.save(filedir)\n",
        "    clean_env()\n",
        "    if IMAGE_UPSCALER == \"GFPGAN\":\n",
        "      print('Face Enhancing and Upscaling... ')\n",
        "      %cd GFPGAN\n",
        "      try:\n",
        "        !python /content/GFPGAN/inference_gfpgan.py -i $filedir -o $OUTDIR -v 1.3 -s $UPSCALE_AMOUNT --bg_upsampler realesrgan\n",
        "      except FileNotFoundError:\n",
        "        ESRGAN_install()\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(PIL.Image.open(f'{OUTDIR}/restored_imgs/{filename}'))\n",
        "      %cd ..\n",
        "      print(f'Moving enhanced image to {OUTDIR}')\n",
        "      old_filedir = filedir\n",
        "      filedir = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      shutil.move(f'{OUTDIR}/restored_imgs/{filename}', filedir)\n",
        "      try:\n",
        "        if DELETE_ORIGINALS:\n",
        "          os.remove(old_filedir)\n",
        "      except FileNotFoundError:\n",
        "        pass\n",
        "      clean_env()\n",
        "    if IMAGE_UPSCALER == \"Enhanced Real-ESRGAN\":\n",
        "      print('Upscaling... ')\n",
        "      sr_image = upscale(image)\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(sr_image)\n",
        "      old_filedir = filedir\n",
        "      try:\n",
        "        filedir = f'{OUTDIR}/{str(epoch_time)}_scale_{SCALE}_steps_{STEPS}_seed_{rand_num}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      except NameError:\n",
        "        filedir = f'{OUTDIR}/{str(epoch_time)}_scale_{SCALE}_steps_{STEPS}_seed_{SEED}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      sr_image.save(filedir)\n",
        "      if DELETE_ORIGINALS:\n",
        "        os.remove(old_filedir)\n",
        "      clean_env()\n",
        "    if IMAGE_UPSCALER == \"GFPGAN + Enhanced ESRGAN\":\n",
        "      print('Face Enhancing... ')\n",
        "      %cd GFPGAN\n",
        "      try:\n",
        "        !python /content/GFPGAN/inference_gfpgan.py -i $filedir -o $OUTDIR -v 1.3 -s 1 --bg_upsampler realesrgan\n",
        "      except FileNotFoundError:\n",
        "        ESRGAN_install()\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(PIL.Image.open(f'{OUTDIR}/restored_imgs/{filename}'))\n",
        "      %cd ..\n",
        "      shutil.copy(f'{OUTDIR}/restored_imgs/{filename}', f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "      clean_env()\n",
        "      print('Upscaling... ')\n",
        "      sr_image = upscale(PIL.Image.open(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'))\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(sr_image)\n",
        "      old_filedir = filedir\n",
        "      try:\n",
        "        filedir = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      except NameError:\n",
        "        filedir = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      sr_image.save(filedir)\n",
        "      if DELETE_ORIGINALS:\n",
        "        try:\n",
        "          os.remove(old_filedir)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "      clean_env()\n",
        "    if IMAGE_UPSCALER == \"CodeFormer\":\n",
        "      print(\"Face enhancing and Upscaling... \")\n",
        "      # It was behaving weird, hence why I am doing this the weird way\n",
        "      try:\n",
        "        !rm rm /content/CodeFormer/temp/*\n",
        "        !cp $filedir /content/CodeFormer/temp/\n",
        "      except Exception as e:\n",
        "        os.makedirs('/content/CodeFormer/temp/')\n",
        "        !cp $filedir /content/CodeFormer/temp/\n",
        "      %cd /content/CodeFormer/\n",
        "      !python inference_codeformer.py --w $CODEFORMER_FIDELITY --test_path /content/CodeFormer/temp --upscale $UPSCALE_AMOUNT --bg_upsampler realesrgan\n",
        "      old_filedir = filedir\n",
        "      filedir = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      shutil.copyfile(f'/content/CodeFormer/results/temp_{CODEFORMER_FIDELITY}/final_results/{filename}', filedir)\n",
        "      os.remove(f'/content/CodeFormer/temp/{filename}')\n",
        "      if DELETE_ORIGINALS:\n",
        "        try:\n",
        "          os.remove(old_filedir)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "      %cd /content\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(PIL.Image.open(filedir))\n",
        "      clean_env()\n",
        "    if IMAGE_UPSCALER == \"CodeFormer + Enhanced ESRGAN\":\n",
        "      print(\"Face enhancing... \")\n",
        "      try:\n",
        "        !rm /content/CodeFormer/temp/*\n",
        "        !cp $filedir /content/CodeFormer/temp/\n",
        "      except Exception as e:\n",
        "        os.makedirs('/content/CodeFormer/temp/')\n",
        "        !cp $filedir /content/CodeFormer/temp/\n",
        "      %cd /content/CodeFormer/\n",
        "      !python inference_codeformer.py --w $CODEFORMER_FIDELITY --test_path /content/CodeFormer/temp --upscale 1 --bg_upsampler realesrgan\n",
        "      os.remove(f'/content/CodeFormer/temp/{filename}')\n",
        "      shutil.copyfile(f'/content/CodeFormer/results/temp_{CODEFORMER_FIDELITY}/final_results/{filename}', f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "      %cd /content\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(PIL.Image.open(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'))\n",
        "      clean_env()\n",
        "      print(\"Upscaling... \")\n",
        "      sr_image = upscale(PIL.Image.open(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'))\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(sr_image)\n",
        "      old_filedir = filedir\n",
        "      filedir = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png'\n",
        "      sr_image.save(filedir)\n",
        "      if DELETE_ORIGINALS:\n",
        "        try:\n",
        "          os.remove(old_filedir)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "      clean_env()\n",
        "    if int(SHARPEN_AMOUNT) != 0:\n",
        "      def sharpenImage(image, samples=1):\n",
        "        im = image\n",
        "        for i in range(samples):\n",
        "            im = im.filter(ImageFilter.SHARPEN)\n",
        "        return im\n",
        "      print(f\"Sharpening diffusion result with {SHARPEN_AMOUNT} passes.\\n\")\n",
        "      image = sharpenImage(PIL.Image.open(filedir), SHARPEN_AMOUNT)\n",
        "      if not SKIP_PREVIEW:\n",
        "        display(image)\n",
        "      old_filedir = filedir\n",
        "      filedir = f'{filedir.strip(\".png\")}_sharpened_{SHARPEN_AMOUNT}.png'\n",
        "      image.save(filedir)\n",
        "      if DELETE_ORIGINALS:\n",
        "        try:\n",
        "          os.remove(old_filedir)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "\n",
        "def get_generator(seed):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"succinctly/text2image-prompt-generator\")\n",
        "  model = AutoModelForCausalLM.from_pretrained(\"succinctly/text2image-prompt-generator\")\n",
        "  generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "  set_seed(seed)\n",
        "  return generator\n",
        "\n",
        "def text_generator(samples, generator):\n",
        "  Otype = 'i'\n",
        "  if type(samples) is str:\n",
        "    s = samples\n",
        "  elif len(samples) == 1:\n",
        "    s = samples[0]\n",
        "  else:\n",
        "    s = samples\n",
        "    Otype = 'b'\n",
        "\n",
        "  if Otype == 'i':\n",
        "    o = [generator(s)[0]['generated_text']]\n",
        "  else:\n",
        "    o = [i[0]['generated_text'] for i in generator(s)]\n",
        "  return o\n",
        "\n",
        "def prompt_styler(prompts):\n",
        "  # with open(style_config, 'r') as pf:\n",
        "  #   config = json.load(pf)\n",
        "  # print(config)\n",
        "  config = {\n",
        "    \"main\": [\n",
        "      \"a painting of\",\n",
        "      \"a digital art of\",\n",
        "      \"a digital painting of\"\n",
        "    ],\n",
        "    \"artist\": [\n",
        "      \"by Charlie Bowater\",\n",
        "      \"by Bastien Lecouffe-Deharme\",\n",
        "      \"by Yoshitaka Amano\",\n",
        "      \"by Karol Bak \",\n",
        "      \"by Yoann Lossel\",\n",
        "      \"by Peter Mohrbacher\",\n",
        "      \"by Ryohei Hase\",\n",
        "      \"by Lü Ji\",\n",
        "      \"by tooth wu\",\n",
        "      \"by greg rutkowski\",\n",
        "      \"by gaston bussiere\",\n",
        "\n",
        "      \"by yoshitaka amano\",\n",
        "      \"by tsutomu nihei\",\n",
        "      \"by donato giancola\",\n",
        "      \"by tim hildebrandt\"\n",
        "    ],\n",
        "    \"style\": [\n",
        "      \"Cgsociety\",\n",
        "      \"Poster art\",\n",
        "      \"Digital painting\",\n",
        "      \"Steampunk\",\n",
        "      \"Gothic art\",\n",
        "      \"Dystopian art\",\n",
        "      \"Fantasy art\",\n",
        "      \"Matte painting\",\n",
        "      \"Cinematic lighting\",\n",
        "      \"focus , sharp\",\n",
        "      \"huge scene\",\n",
        "      \"unreal 5\",\n",
        "      \"hyper realism\",\n",
        "      \"ultra detailed fantasy\",\n",
        "      \"lotr game design fanart by concept art\",\n",
        "      \"devinart\",\n",
        "      \"concept art\",\n",
        "      \"fantasy character portrait\",\n",
        "      \"extreme detail\"\n",
        "    ]\n",
        "  }\n",
        "  # filter any random artist\n",
        "  prompts = [p[:p.find('by')] for p in prompts]\n",
        "\n",
        "  new_prompts = [\n",
        "      \"{main} {i}, {artist}, {style}, detailed, pixiv\".format(main=choice(config['main']), i=i, artist=', '.join(sample(config['artist'], 3)), style=', '.join(sample(config['style'], 3)))\n",
        "      for i in prompts\n",
        "  ]\n",
        "  return new_prompts\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "  stop_its = False\n",
        "  %cd /content/\n",
        "  #@title Synthesize Images\n",
        "  MODE = \"PROMPT\"\n",
        "  #@markdown `MODE` Select what mode you want to use <br>\n",
        "  PROMPT = \"Beautiful warrior girl\" #@param {type:'string'}\n",
        "  #@markdown `PROMPT` The text prompt that is needed for all modes <br>\n",
        "  PROMPT_FILE = '' #@param {type: 'string'}\n",
        "  #@markdown `PROMPT_FILE` is a text file that contains a prompt per line. <br>\n",
        "  GENERATE_PROMPT = True\n",
        "  STYLE_PROMPT = 'style' #@param ['none', 'style', 'random']\n",
        "\n",
        "  # #@markdown ---\n",
        "\n",
        "  # #@markdown <b>Init Image Setup (IMG2IMG)</b><br>\n",
        "  # #@markdown Still a work in progress, might be buggy<br>\n",
        "\n",
        "  # INIT_IMAGE = \"https://raw.githubusercontent.com/dblunk88/txt2imghd/master/character_with_hat.jpg\" #@param {type: 'string'}\n",
        "  # #@markdown `INIT_IMAGE`: Can be a local file, URL, or empty (to make your own in colab)<br>\n",
        "  # INIT_STRENGTH = 0.92 #@param{type:\"slider\", min:0.01, max:1, step:0.01}\n",
        "  # #@markdown `INIT_STRENGTH`: The <B>LOWER</B> this values is, the more strength the init file has on the final output\n",
        "\n",
        "  # # @markdown ---\n",
        "\n",
        "  # #@markdown <b>INPAINT Setup</b><br>\n",
        "  # #@markdown Still a work in progress, might be buggy<br>\n",
        "  # #@markdown `INPAINT_IMAGE` can be a local file or URL<br>\n",
        "  # #@markdown `MASK_IMAGE` can be a local file, URL, or empty. If empty, you get to draw your mask within the colab\n",
        "  # INPAINT_IMAGE = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\" #@param {type:'string'}\n",
        "  # MASK_IMAGE = \"\" #@param {type:'string'}\n",
        "  # INPAINT_STRENGTH = 0.96 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "  #@markdown ---\n",
        "  STEPS = 100\n",
        "  SCHEDULER = 'ddim'\n",
        "  DDIM_ETA = 0.9\n",
        "  #@markdown Getting good results with `ddim` and `DDIM_ETA` at 0.9\n",
        "  #@markdown Diffusion steps determine the quality of the final image\n",
        "  SEED = 1234 #@param {type:'integer'}\n",
        "  #@markdown The seed used for the generation. Leave at `0` for random.\n",
        "  KEEP_SEED = False\n",
        "  #@markdown Will force the program to keep the same seed throughout the iterations.\n",
        "  NUM_ITERS = 6 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "  RUN_FOREVER = False #@param {type:\"boolean\"}\n",
        "  #@markdown Number of iterations for a given prompt.\n",
        "  WIDTH = 512 #@param {type:\"slider\", min:256, max:4096, step:64}\n",
        "  HEIGHT = 512 #@param {type:\"slider\", min:256, max:4096, step:64}\n",
        "  SCALE = 13.8\n",
        "\n",
        "  PRECISION = \"autocast\"\n",
        "  #@markdown If you're using the `low VRAM patch` you <b>HAVE</b> to use `autocast`<br>\n",
        "  SAVE_PROMPT_DETAILS = True #@param {type:\"boolean\"}\n",
        "  USE_DRIVE_FOR_PICS = True #@param {type:\"boolean\"}\n",
        "  DRIVE_PIC_DIR = \"sample_pics\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "  IMAGE_UPSCALER = \"Enhanced Real-ESRGAN\"\n",
        "  UPSCALE_AMOUNT = 4\n",
        "\n",
        "  CODEFORMER_FIDELITY = 0.8\n",
        "\n",
        "  SHARPEN_AMOUNT = 0\n",
        "  DELETE_ORIGINALS = True\n",
        "  #@markdown `SKIP_PREVIEW`: Clicking this might help with connection issues (especially on mobile). It will only show the original result, not the improvements\n",
        "  SKIP_PREVIEW = True #@param{type:'boolean'}\n",
        "\n",
        "  MODEL_ID = \"CompVis/stable-diffusion-v1-4\"\n",
        "  model_id = MODEL_ID\n",
        "  DIFFUSERS_VERSION = 'latest'\n",
        "  LOW_VRAM_PATCH = False\n",
        "  VRAM_OVER_SPEED = True\n",
        "  ENABLE_NSFW_FILTER = False\n",
        "  CLEAR_SETUP_LOG = True\n",
        "  #@markdown ---\n",
        "\n",
        "  ##@markdown <b>Advanced Options</b><br>\n",
        "  ##@markdown If you don't know what you are doing, do NOT touch this<br>\n",
        "\n",
        "\n",
        "  #     pipe.scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, skip_prk_steps=True)\n",
        "  # elif SCHEDULER == 'pndm':\n",
        "  #   pipe.scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, skip_prk_steps=True)\n",
        "  # elif SCHEDULER == 'k-lms':\n",
        "  #   pipe.scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "  # elif SCHEDULER == 'ddim':\n",
        "  #   pipe.scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "\n",
        "\n",
        "  # Need to clean up imports\n",
        "  try:\n",
        "    import os, torch, gc\n",
        "  except ValueError:\n",
        "    !yes | pip uninstall numpy\n",
        "    !pip install -U numpy\n",
        "    import os, torch, gc\n",
        "  from PIL import Image\n",
        "  import random, time, shutil, sys\n",
        "  from contextlib import contextmanager, nullcontext\n",
        "  from torch import autocast\n",
        "  from IPython.display import clear_output\n",
        "  import numpy as np\n",
        "  import PIL.Image\n",
        "  import PIL\n",
        "  from PIL import ImageFilter\n",
        "  import json\n",
        "  from random import sample, choice\n",
        "  # Google Drive\n",
        "  if USE_DRIVE_FOR_PICS and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "  if USE_DRIVE_FOR_PICS and not os.path.exists(f'/content/drive/MyDrive/{DRIVE_PIC_DIR}'):\n",
        "    !mkdir /content/drive/MyDrive/$DRIVE_PIC_DIR\n",
        "  if USE_DRIVE_FOR_PICS:\n",
        "    OUTDIR = f'/content/drive/MyDrive/{DRIVE_PIC_DIR}'\n",
        "  else:\n",
        "    OUTDIR = '/content/diffusers_output'\n",
        "  try:\n",
        "    os.makedirs(OUTDIR)\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    from diffusers.schedulers import PNDMScheduler, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
        "    from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "  except ModuleNotFoundError or ImportError:\n",
        "    diffusers_install()\n",
        "    from diffusers.schedulers import PNDMScheduler, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
        "    from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "  # Decide precision and set variables\n",
        "  precision_scope = autocast if PRECISION==\"autocast\" else nullcontext\n",
        "  ORIG_SEED = SEED\n",
        "  DRIVE_PIC_DIR = DRIVE_PIC_DIR.strip()\n",
        "\n",
        "  # import text2image prompt generator\n",
        "  # if STYLE_PROMPT in ['style', 'random']:\n",
        "  from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, set_seed\n",
        "\n",
        "  # Enable third-party widgets\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "\n",
        "\n",
        "  # Split this into a function\n",
        "  #  INPAINT_IMAGE = \"https://pbs.twimg.com/media/FbwYUfXaMAATXEj?format=jpg&name=large\" #@param {type:'string'}\n",
        "  # MASK_IMAGE = \"\" #@param {type:'string'}\n",
        "  # INPAINT_STRENGTH = 0.96 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "  if MODE == \"Inpainting\":\n",
        "    def download_image(url):\n",
        "      import requests\n",
        "      from io import BytesIO\n",
        "      response = requests.get(url)\n",
        "      return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    if 'http' in INPAINT_IMAGE:\n",
        "      INPAINT_IMAGE = download_image(INPAINT_IMAGE).resize((WIDTH, HEIGHT))\n",
        "    elif INPAINT_IMAGE:\n",
        "      INPAINT_IMAGE = PIL.Image.open(INPAINT_IMAGE)\n",
        "    if 'http' in MASK_IMAGE:\n",
        "      MASK_IMAGE = download_image(MASK_IMAGE).resize((WIDTH, HEIGHT))\n",
        "    elif MASK_IMAGE:\n",
        "      MASK_IMAGE = PIL.Image.open(MASK_IMAGE)\n",
        "    INPAINT_IMAGE.save(\"init.jpg\")\n",
        "    if not MASK_IMAGE:\n",
        "      import requests\n",
        "      from io import BytesIO\n",
        "      def draw(filename='drawing.png', color=\"white\", w=256, h=256, line_width=50,loop=False, init_img=\"init.jpg\"):\n",
        "        filename=\"init.jpg\"\n",
        "        import google\n",
        "        from IPython.display import HTML\n",
        "        from base64 import b64decode\n",
        "        import os\n",
        "        import shutil\n",
        "        import uuid\n",
        "        COLAB_HTML_ROOT = \"/usr/local/share/jupyter/nbextensions/google.colab/\"\n",
        "\n",
        "        def moveToExt(filename:str) -> str:\n",
        "          if not os.path.exists(filename):\n",
        "            print(\"Image file not found\")\n",
        "            return None\n",
        "\n",
        "          target = os.path.basename(filename)\n",
        "          target = os.path.join(COLAB_HTML_ROOT, str(uuid.uuid4()) + target)\n",
        "\n",
        "          shutil.copyfile(filename,target)\n",
        "          print(\"moved to ext\")\n",
        "          return target\n",
        "        real_filename = os.path.realpath(filename)\n",
        "        html_filename = real_filename\n",
        "        html_real_filename = html_filename\n",
        "        if os.path.exists(real_filename):\n",
        "          html_real_filename = moveToExt(real_filename)\n",
        "          html_filename = html_real_filename.replace(\"/usr/local/share/jupyter\",\"\")\n",
        "\n",
        "\n",
        "        canvas_html = f\"\"\"\n",
        "      <canvas width={w} height={h}></canvas>\n",
        "\n",
        "      <div class=\"slidecontainer\">\n",
        "      <label for=\"lineWidth\" id=\"lineWidthLabel\">{line_width}px</label>\n",
        "        <input type=\"range\" min=\"1\" max=\"100\" value=\"1\" class=\"slider\" id=\"lineWidth\">\n",
        "      </div>\n",
        "\n",
        "      <div>\n",
        "        <button id=\"loadImage\">Reload from disk</button>\n",
        "        <button id=\"reset\">Reset</button>\n",
        "        <button id=\"save\">Save</button>\n",
        "      </div>\n",
        "      <script>\n",
        "\n",
        "      function loadImage(url) {{\n",
        "      return new Promise(r => {{ let i = new Image(); i.onload = (() => r(i)); i.src = url; }});\n",
        "      }}\n",
        "\n",
        "\n",
        "        var canvas = document.querySelector('canvas')\n",
        "        var ctx = canvas.getContext('2d')\n",
        "        ctx.lineWidth = {line_width};\n",
        "\n",
        "        ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "        ctx.strokeStyle = \"{color}\";\n",
        "\n",
        "\n",
        "        var slider = document.getElementById(\"lineWidth\");\n",
        "        slider.oninput = function() {{\n",
        "          ctx.lineWidth = this.value;\n",
        "          lineWidthLabel.innerHTML = `${{this.value}}px`\n",
        "        }}\n",
        "\n",
        "\n",
        "        function updateStroke(event){{\n",
        "            ctx.strokeStyle = event.target.value\n",
        "        }}\n",
        "        function updateBG(event){{\n",
        "            ctx.fillStyle = event.target.value\n",
        "        }}\n",
        "\n",
        "\n",
        "        var clear_button = document.querySelector('#reset')\n",
        "        var reload_img_button = document.querySelector('#loadImage')\n",
        "\n",
        "        var button = document.querySelector('#save')\n",
        "\n",
        "        var mouse = {{x: 0, y: 0}}\n",
        "        canvas.addEventListener('mousemove', function(e) {{\n",
        "          mouse.x = e.pageX - this.offsetLeft\n",
        "          mouse.y = e.pageY - this.offsetTop\n",
        "        }})\n",
        "        canvas.onmousedown = ()=>{{\n",
        "          ctx.beginPath()\n",
        "          ctx.moveTo(mouse.x, mouse.y)\n",
        "          canvas.addEventListener('mousemove', onPaint)\n",
        "        }}\n",
        "        canvas.onmouseup = ()=>{{\n",
        "          canvas.removeEventListener('mousemove', onPaint)\n",
        "        }}\n",
        "        var onPaint = ()=>{{\n",
        "          ctx.lineTo(mouse.x, mouse.y)\n",
        "          ctx.stroke()\n",
        "        }}\n",
        "        reload_img_button.onclick = async ()=>{{\n",
        "          console.log(\"Reloading Image {html_filename}\")\n",
        "          let img = await loadImage('{html_filename}');\n",
        "          console.log(\"Loaded image\")\n",
        "          ctx.drawImage(img, 0, 0);\n",
        "\n",
        "        }}\n",
        "        reload_img_button.click()\n",
        "\n",
        "        clear_button.onclick = ()=>{{\n",
        "            console.log('Clearing Screen')\n",
        "            ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "            ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "          }}\n",
        "          canvas.addEventListener('load', function() {{\n",
        "          console.log('All assets are loaded')\n",
        "        }})\n",
        "        var data = new Promise(resolve=>{{\n",
        "          button.onclick = ()=>{{\n",
        "\n",
        "            var c = ctx\n",
        "            var imageData = ctx.getImageData(0,0, {w}, {h});\n",
        "            var pixel = imageData.data;\n",
        "            var r=0, g=1, b=2,a=3;\n",
        "          for (var p = 0; p<pixel.length; p+=4)\n",
        "          {{\n",
        "            if (\n",
        "                pixel[p+r] != 255 &&\n",
        "                pixel[p+g] != 255 &&\n",
        "                pixel[p+b] != 255)\n",
        "            {{pixel[p+r] =0; pixel[p+g]=0; pixel[p+b]=0}}\n",
        "          }}\n",
        "\n",
        "          c.putImageData(imageData,0,0);\n",
        "            resolve(canvas.toDataURL('image/png'))\n",
        "          }}\n",
        "\n",
        "        }})\n",
        "\n",
        "\n",
        "      </script>\n",
        "      \"\"\"\n",
        "        print(HTML)\n",
        "        display(HTML(canvas_html))\n",
        "        print(\"Evaluating JS\")\n",
        "\n",
        "        data = google.colab.output.eval_js(\"data\")\n",
        "        if data:\n",
        "          print(\"Saving Sketch\")\n",
        "          binary = b64decode(data.split(',')[1])\n",
        "          # filename = html_real_filename if loop else filename\n",
        "          with open(\"init_mask.png\", 'wb') as f:\n",
        "            f.write(binary)\n",
        "          #return len(binary)\n",
        "\n",
        "\n",
        "\n",
        "      draw(filename = \"init_mask.png\", w=WIDTH, h=HEIGHT)\n",
        "      MASK_IMAGE = PIL.Image.open('init_mask.png')\n",
        "  if MODE == \"IMG2IMG\":\n",
        "    if 'http' in INIT_IMAGE:\n",
        "      import requests\n",
        "      from io import BytesIO\n",
        "      response = requests.get(INIT_IMAGE)\n",
        "      init_image = PIL.Image.open(BytesIO(response.content))\n",
        "      INIT_IMAGE = init_image\n",
        "    else:\n",
        "      if INIT_IMAGE == None or INIT_IMAGE == \"\":\n",
        "        if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "        print(\"No init image found, go ahead and draw your own below this text\")\n",
        "        def draw(filename='drawing.png', color=\"black\", bg_color=\"transparent\",w=256, h=256, line_width=1,loop=False):\n",
        "          import google\n",
        "          from IPython.display import HTML\n",
        "          from base64 import b64decode\n",
        "          import os\n",
        "          import shutil\n",
        "          import uuid\n",
        "          COLAB_HTML_ROOT = \"/usr/local/share/jupyter/nbextensions/google.colab/\"\n",
        "\n",
        "          def moveToExt(filename:str) -> str:\n",
        "            if not os.path.exists(filename):\n",
        "              print(\"Image file not found\")\n",
        "              return None\n",
        "\n",
        "            target = os.path.basename(filename)\n",
        "            target = os.path.join(COLAB_HTML_ROOT, str(uuid.uuid4()) + target)\n",
        "\n",
        "            shutil.copyfile(filename,target)\n",
        "            print(\"moved to ext\")\n",
        "            return target\n",
        "          real_filename = os.path.realpath(filename)\n",
        "          html_filename = real_filename\n",
        "          html_real_filename = html_filename\n",
        "          if os.path.exists(real_filename):\n",
        "            html_real_filename = moveToExt(real_filename)\n",
        "            html_filename = html_real_filename.replace(\"/usr/local/share/jupyter\",\"\")\n",
        "\n",
        "\n",
        "          canvas_html = f\"\"\"\n",
        "        <canvas width={w} height={h}></canvas>\n",
        "        <div>\n",
        "          <label for=\"strokeColor\">Stroke</label>\n",
        "          <input type=\"color\" value=\"{color}\" id=\"strokeColor\">\n",
        "\n",
        "          <label for=\"bgColor\">Background</label>\n",
        "          <input type=\"color\" value=\"{bg_color}\" id=\"bgColor\">\n",
        "        </div>\n",
        "        <div class=\"slidecontainer\">\n",
        "        <label for=\"lineWidth\" id=\"lineWidthLabel\">{line_width}px</label>\n",
        "          <input type=\"range\" min=\"1\" max=\"35\" value=\"1\" class=\"slider\" id=\"lineWidth\">\n",
        "        </div>\n",
        "\n",
        "        <div>\n",
        "          <button id=\"loadImage\">Reload from disk</button>\n",
        "          <button id=\"reset\">Reset</button>\n",
        "          <button id=\"save\">Save</button>\n",
        "          <button id=\"exit\">Exit</button>\n",
        "        </div>\n",
        "        <script>\n",
        "\n",
        "        function loadImage(url) {{\n",
        "        return new Promise(r => {{ let i = new Image(); i.onload = (() => r(i)); i.src = url; }});\n",
        "      }}\n",
        "\n",
        "\n",
        "          var canvas = document.querySelector('canvas')\n",
        "          var ctx = canvas.getContext('2d')\n",
        "          ctx.lineWidth = {line_width}\n",
        "          ctx.fillStyle = \"{bg_color}\";\n",
        "\n",
        "          ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "          ctx.strokeStyle = \"{color}\";\n",
        "\n",
        "          var strokeColor = document.querySelector('#strokeColor')\n",
        "          var bgColor = document.querySelector('#bgColor')\n",
        "\n",
        "          var slider = document.getElementById(\"lineWidth\");\n",
        "          slider.oninput = function() {{\n",
        "            ctx.lineWidth = this.value;\n",
        "            lineWidthLabel.innerHTML = `${{this.value}}px`\n",
        "          }}\n",
        "\n",
        "          function updateStroke(event){{\n",
        "              ctx.strokeStyle = event.target.value\n",
        "          }}\n",
        "          function updateBG(event){{\n",
        "              ctx.fillStyle = event.target.value\n",
        "          }}\n",
        "\n",
        "          bgColor.addEventListener(\"change\", updateBG, false);\n",
        "          strokeColor.addEventListener(\"change\", updateStroke, false);\n",
        "\n",
        "          var clear_button = document.querySelector('#reset')\n",
        "          var reload_img_button = document.querySelector('#loadImage')\n",
        "          var button = document.querySelector('#save')\n",
        "          var exit_button = document.querySelector('#exit')\n",
        "\n",
        "          var mouse = {{x: 0, y: 0}}\n",
        "          canvas.addEventListener('mousemove', function(e) {{\n",
        "            mouse.x = e.pageX - this.offsetLeft\n",
        "            mouse.y = e.pageY - this.offsetTop\n",
        "          }})\n",
        "          canvas.onmousedown = ()=>{{\n",
        "            ctx.beginPath()\n",
        "            ctx.moveTo(mouse.x, mouse.y)\n",
        "            canvas.addEventListener('mousemove', onPaint)\n",
        "          }}\n",
        "          canvas.onmouseup = ()=>{{\n",
        "            canvas.removeEventListener('mousemove', onPaint)\n",
        "          }}\n",
        "          var onPaint = ()=>{{\n",
        "            ctx.lineTo(mouse.x, mouse.y)\n",
        "            ctx.stroke()\n",
        "          }}\n",
        "          reload_img_button.onclick = async ()=>{{\n",
        "            console.log(\"Reloading Image {html_filename}\")\n",
        "            let img = await loadImage('{html_filename}');\n",
        "            console.log(\"Loaded image\")\n",
        "            ctx.drawImage(img, 0, 0);\n",
        "\n",
        "          }}\n",
        "\n",
        "          clear_button.onclick = ()=>{{\n",
        "              console.log('Clearing Screen')\n",
        "              ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "              ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "            }}\n",
        "            canvas.addEventListener('load', function() {{\n",
        "            console.log('All assets are loaded')\n",
        "          }})\n",
        "          var data = new Promise(resolve=>{{\n",
        "            button.onclick = ()=>{{\n",
        "              resolve(canvas.toDataURL('image/png'))\n",
        "            }}\n",
        "            exit_button.onclick = ()=>{{\n",
        "            resolve()\n",
        "          }}\n",
        "\n",
        "          }})\n",
        "\n",
        "          // window.onload = async ()=>{{\n",
        "          //   console.log(\"loaded\")\n",
        "          //   let img = await loadImage('{html_filename}');\n",
        "          //   ctx.drawImage(img, 0, 0);\n",
        "          // }}\n",
        "\n",
        "\n",
        "        </script>\n",
        "        \"\"\"\n",
        "          print(HTML)\n",
        "          display(HTML(canvas_html))\n",
        "          print(\"Evaluating JS\")\n",
        "\n",
        "          data = google.colab.output.eval_js(\"data\")\n",
        "          if data:\n",
        "            print(\"Saving Sketch\")\n",
        "            binary = b64decode(data.split(',')[1])\n",
        "            # filename = html_real_filename if loop else filename\n",
        "            with open(filename, 'wb') as f:\n",
        "              f.write(binary)\n",
        "            #return len(binary)\n",
        "\n",
        "\n",
        "\n",
        "        draw(filename = \"custom_image.png\", w=WIDTH, h=HEIGHT, bg_color=\"blue\", line_width=10)\n",
        "        INIT_IMAGE = \"/content/custom_image.png\"\n",
        "      INIT_IMAGE = PIL.Image.open(INIT_IMAGE)\n",
        "\n",
        "  # Check if upscalers are installed\n",
        "  if \"GFPGAN\" in IMAGE_UPSCALER:\n",
        "    GFPGAN_install()\n",
        "  if \"ESRGAN\"in IMAGE_UPSCALER:\n",
        "    ESRGAN_install()\n",
        "  if \"CodeFormer\" in IMAGE_UPSCALER:\n",
        "    CodeFormer_install()\n",
        "\n",
        "  try:\n",
        "    if MODE != LAST_MODE or LOW_VRAM_PATCH != LAST_VRAM or ENABLE_NSFW_FILTER != LAST_ENABLE_NSFW_FILTER or LAST_MODEL_ID != MODEL_ID or LAST_DIFFUSERS_VERSION != DIFFUSERS_VERSION:\n",
        "      print(\"Pipe specific settings have changed, repopulating pipe with new settings...\")\n",
        "      populate()\n",
        "  except NameError:\n",
        "    LAST_MODE = MODE\n",
        "    LAST_VRAM = LOW_VRAM_PATCH\n",
        "    LAST_ENABLE_NSFW_FILTER = ENABLE_NSFW_FILTER\n",
        "    LAST_MODEL_ID = MODEL_ID\n",
        "    LAST_DIFFUSERS_VERSION = DIFFUSERS_VERSION\n",
        "  if CLEAR_SETUP_LOG: from IPython.display import clear_output; clear_output()\n",
        "  # Make this into a function and create a function for anything repititive\n",
        "  PROMPTS = []\n",
        "  if PROMPT_FILE not in ['','none']:\n",
        "      try:\n",
        "          with open(PROMPT_FILE, \"r\") as f:\n",
        "              PROMPTS = f.read().splitlines()\n",
        "      except OSError as e:\n",
        "          raise e\n",
        "\n",
        "  if PROMPT not in ['', 'none']:\n",
        "      PROMPTS.insert(0, PROMPT)\n",
        "\n",
        "  if (GENERATE_PROMPT == True) and (STYLE_PROMPT == 'style'):\n",
        "    generator = get_generator(SEED)\n",
        "    PROMPTS = text_generator(PROMPTS, generator)\n",
        "    PROMPTS = prompt_styler(PROMPTS)\n",
        "  elif (GENERATE_PROMPT == True) and (STYLE_PROMPT == 'none'):\n",
        "    generator = get_generator(SEED)\n",
        "    PROMPTS = text_generator(PROMPTS, generator)\n",
        "  elif (GENERATE_PROMPT == True) and (STYLE_PROMPT == 'random'):\n",
        "    generator = get_generator(SEED)\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    with precision_scope(\"cuda\"):\n",
        "        if RUN_FOREVER:\n",
        "          while True:\n",
        "            for pi in PROMPTS:\n",
        "              PROMPT = pi\n",
        "              if (GENERATE_PROMPT == True) and (STYLE_PROMPT == 'random'):\n",
        "                PROMPT = prompt_styler(text_generator(PROMPT, generator))[0]\n",
        "              print(OUTDIR)\n",
        "              if SAVE_PROMPT_DETAILS:\n",
        "                  epoch_time = int(time.time())\n",
        "                  try:\n",
        "                    with open(f'{OUTDIR}/{epoch_time}_prompt.txt', 'w') as file:\n",
        "                        file.write(f'{PROMPT}\\n\\nHeight: {HEIGHT}\\nWidth: {WIDTH}\\nSeed: {SEED}\\nScale: {SCALE}\\nPrecision: {PRECISION}\\nETA: {DDIM_ETA}\\nINIT_STRENGTH: {INIT_STRENGTH}\\nSCHEDULER: {SCHEDULER}')\n",
        "                  except FileNotFoundError:\n",
        "                    os.makedirs(OUTDIR)\n",
        "              for iteration in range(NUM_ITERS):\n",
        "                clean_env()\n",
        "                try:\n",
        "                  diffuse_run()\n",
        "                except KeyboardInterrupt:\n",
        "                  stop_its = True\n",
        "                  import os\n",
        "                  clean_env()\n",
        "                  try:\n",
        "                    image = None\n",
        "                  except Exception:\n",
        "                    pass\n",
        "                  raise SystemExit('\\33[33mExecution interrupted by user.\\33[0m')\n",
        "                except TypeError:\n",
        "                  make_pipe()\n",
        "                  make_scheduler()\n",
        "                  try:\n",
        "                    diffuse_run()\n",
        "                  except KeyboardInterrupt:\n",
        "                    stop_its = True\n",
        "                    import os\n",
        "                    clean_env()\n",
        "                    try:\n",
        "                      image = None\n",
        "                    except Exception:\n",
        "                      pass\n",
        "                    raise SystemExit('\\33[33mExecution interrupted by user.\\33[0m')\n",
        "                clean_env()\n",
        "        else:\n",
        "          for pi in PROMPTS:\n",
        "              PROMPT = pi\n",
        "              if (GENERATE_PROMPT == True) and (STYLE_PROMPT == 'random'):\n",
        "                PROMPT = prompt_styler(text_generator(PROMPT, generator))[0]\n",
        "              print(OUTDIR)\n",
        "              if SAVE_PROMPT_DETAILS:\n",
        "                  epoch_time = int(time.time())\n",
        "                  try:\n",
        "                    with open(f'{OUTDIR}/{epoch_time}_prompt.txt', 'w') as file:\n",
        "                        file.write(f'{PROMPT}\\n\\nHeight: {HEIGHT}\\nWidth: {WIDTH}\\nSeed: {SEED}\\nScale: {SCALE}\\nPrecision: {PRECISION}\\nETA:{DDIM_ETA}')\n",
        "                  except FileNotFoundError:\n",
        "                    os.makedirs(OUTDIR)\n",
        "              for iteration in range(NUM_ITERS):\n",
        "                clean_env()\n",
        "                try:\n",
        "                  diffuse_run()\n",
        "                except KeyboardInterrupt:\n",
        "                  stop_its = True\n",
        "                  import os\n",
        "                  clean_env()\n",
        "                  try:\n",
        "                    image = None\n",
        "                  except Exception:\n",
        "                    pass\n",
        "                  raise SystemExit('\\33[33mExecution interrupted by user.\\33[0m')\n",
        "                except TypeError:\n",
        "                  make_pipe()\n",
        "                  make_scheduler()\n",
        "                  try:\n",
        "                    diffuse_run()\n",
        "                  except KeyboardInterrupt:\n",
        "                    stop_its = True\n",
        "                    import os\n",
        "                    clean_env()\n",
        "                    try:\n",
        "                      image = None\n",
        "                    except Exception:\n",
        "                      pass\n",
        "                    raise SystemExit('\\33[33mExecution interrupted by user.\\33[0m')\n",
        "                clean_env()\n",
        "        clean_env()"
      ],
      "metadata": {
        "id": "K3i1TTuMnJkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5740A0MfsZdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}