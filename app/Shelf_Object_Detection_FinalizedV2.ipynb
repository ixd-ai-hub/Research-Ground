{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixd-ai-hub/Research-Ground/blob/project%2FCU-865d7myr5-shelf-object-detection/app/Shelf_Object_Detection_FinalizedV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me5Cf0DTP8qR"
      },
      "source": [
        "## Set up enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXcAY7o66qHY",
        "outputId": "4d44f9d7-ded3-4eb3-9733-f8c3c30059b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HOME: /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FVfzql2BHeb",
        "outputId": "89e0abce-9577-4267-aaf0-6d070fdc2a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulCFds5_vRY",
        "outputId": "f0683ae2-17c2-48ba-9088-62846283919f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-y3b5j42d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-y3b5j42d\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36586 sha256=0c6c6455100c407ccecde264f0f55a70cbe717747fb70d58a45cf89e78b88995\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_nhrs4im/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n",
            "Collecting imagededup\n",
            "  Downloading imagededup-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from imagededup) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from imagededup) (0.15.2+cu118)\n",
            "Requirement already satisfied: Pillow>=9.0 in /usr/local/lib/python3.10/dist-packages (from imagededup) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from imagededup) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup) (1.2.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagededup) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imagededup) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imagededup) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->imagededup) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->imagededup) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->imagededup) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->imagededup) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->imagededup) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->imagededup) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->imagededup) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->imagededup) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->imagededup) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->imagededup) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->imagededup) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->imagededup) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->imagededup) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->imagededup) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->imagededup) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->imagededup) (1.3.0)\n",
            "Installing collected packages: imagededup\n",
            "Successfully installed imagededup-0.3.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.7/58.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow==7.1.2\n",
            "  Downloading Pillow-7.1.2.tar.gz (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pillow\n"
          ]
        }
      ],
      "source": [
        "# install SAM model\n",
        "%cd {HOME}\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!pip install imagededup\n",
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n",
        "!pip install pillow==7.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qRbNeB4Z_0hX",
        "outputId": "39b58d5a-64b7-412f-9985-ab4cdf3d81f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/weights\n"
          ]
        }
      ],
      "source": [
        "# dowload SAM weights\n",
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaOe0soKQFDw"
      },
      "source": [
        "## Init the SAM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKL9JliLAAwy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0djfmChACVS"
      },
      "outputs": [],
      "source": [
        "#  Load Model\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDnLm__ZAJVd"
      },
      "outputs": [],
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
        "#  Automatic Mask Generation\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqEOYDY3R4rd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from matplotlib.patches import Rectangle\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "from imagededup.methods import CNN\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A11KRjZ_Rged"
      },
      "source": [
        "## build Object recongnizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTUq5p_PRkP0"
      },
      "outputs": [],
      "source": [
        "def load_image(path):\n",
        "  image_bgr = cv2.imread(path)\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "  return image_rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGwFdqDbRwbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def detect_objects(image, model, img_encoder, base_labels, base_feats, color_dict, thr=0.75):\n",
        "  # generate segmentations\n",
        "  start = time.perf_counter()\n",
        "  sam_result = model.generate(image)\n",
        "  print(f\"Time taken for inference: {time.perf_counter()-start} milli. sec\")\n",
        "\n",
        "  annotations = []\n",
        "  #plt.figure(figsize=(10,12))\n",
        "  for c in sam_result:\n",
        "    x,y,w,h = [int(i) for i in c['bbox']]\n",
        "\n",
        "    # plt.text(int(x), int(y), str(c['predicted_iou'])[:4])\n",
        "    f = image[y:y+h, x:x+w, :]\n",
        "    # print(f.shape, x,y,w,h, image_rgb.shape)\n",
        "    vec = img_encoder.encode_image(image_array=f)\n",
        "    sims = cosine_similarity(base_feats, vec)\n",
        "    lbl = np.argmax(sims)\n",
        "    cls = labels[lbl]\n",
        "    # print(f, sims[lbl], labels[lbl])\n",
        "    if sims[lbl] > thr:\n",
        "      #plt.gca().add_patch(Rectangle((x,y),w,h,linewidth=1,edgecolor=color_dict[cls],facecolor='none'))\n",
        "      #plt.text(int(x), int(y), cls)\n",
        "      annotations.append({\n",
        "                \"image_id\": 1,\n",
        "                \"annotation_id\": f\"{len(annotations)+1:03}\",\n",
        "                \"target_class\": cls,\n",
        "                \"target_bbox\": [x, y, x+w, y+h]\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "  ##plt.imshow(image)\n",
        "  #plt.show()\n",
        "  return annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW8N5ScxG6fg"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/Shelf/Shelf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQaduRtoHlJg",
        "outputId": "a1d5ab9a-e162-4de9-a0a6-d7743b5c5722"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-11 11:11:11,025: INFO Device set to cpu ..\n",
            "INFO:imagededup.methods.cnn:Device set to cpu ..\n",
            "2023-09-11 11:11:11,032: INFO Initialized: mobilenet_v3_small for feature extraction ..\n",
            "INFO:imagededup.methods.cnn:Initialized: mobilenet_v3_small for feature extraction ..\n",
            "2023-09-11 11:11:11,338: INFO Start: Image encoding generation\n",
            "INFO:imagededup.methods.cnn:Start: Image encoding generation\n",
            "2023-09-11 11:11:18,081: INFO End: Image encoding generation\n",
            "INFO:imagededup.methods.cnn:End: Image encoding generation\n"
          ]
        }
      ],
      "source": [
        "imgencoder = CNN()\n",
        "encoding_map = imgencoder.encode_images(image_dir=base_path+'/Bases')\n",
        "\n",
        "lbl_dict = defaultdict(list)\n",
        "for k,v in encoding_map.items():\n",
        "  lbl = k.split('-')[0]\n",
        "  lbl_dict[lbl].append(v)\n",
        "  # print(k)\n",
        "  # labels.append(k.split('.')[0])\n",
        "  # feats.append(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0Tuc5O87Eaj"
      },
      "outputs": [],
      "source": [
        "lbl_dict['wax']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMGguAb3Ibcz",
        "outputId": "c83be8df-c5a0-4ccd-ec7c-5afae700bf93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-63aa598549d1>:4: RuntimeWarning: Mean of empty slice.\n",
            "  feats.append(np.array(fs).mean(axis=0))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "labels, feats = [], []\n",
        "for l, fs in lbl_dict.items():\n",
        "  labels.append(l)\n",
        "  feats.append(np.array(fs).mean(axis=0))\n",
        "\n",
        "# np.array(lbl_dict['napkins']).mean(axis=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FKQ1GmGNThf"
      },
      "outputs": [],
      "source": [
        "color_dict = dict(zip(labels, ['b','r','g','w']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1YHb6yU8xzQ"
      },
      "outputs": [],
      "source": [
        "feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h472Ma2SWR4"
      },
      "outputs": [],
      "source": [
        "# imgencoder = CNN()\n",
        "# encoding_map = imgencoder.encode_images(image_dir='/content/base/base')\n",
        "# labels, feats = [], []\n",
        "# for k,v in encoding_map.items():\n",
        "#   labels.append(k.split('.')[0])\n",
        "#   feats.append(v)\n",
        "# feats = np.array(feats)\n",
        "\n",
        "# color_dict = dict(zip(labels, ['b','r','g','w']))\n",
        "# # color_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNx366JUQTAW"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gEIuw-tVMhM",
        "outputId": "841d7111-157a-49fd-d812-f04fa139ead8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken for inference: 628.9052740279999 milli. sec\n"
          ]
        }
      ],
      "source": [
        "IMAGE_NAME = base_path+\"/Samples/shell2.jpg\"\n",
        "image_rgb = load_image(IMAGE_NAME)\n",
        "annotations=detect_objects(image_rgb, mask_generator, imgencoder, labels, feats, color_dict, thr=0.76)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ2nOqs-p0Dd",
        "outputId": "29ff93df-d4f8-4de8-dfdc-92a1d372f617"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'image_id': 1,\n",
              "  'annotation_id': '001',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [183, 0, 264, 96]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '002',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [258, 0, 331, 120]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '003',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [374, 614, 455, 719]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '004',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [552, 154, 592, 224]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '005',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [324, 38, 386, 132]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '006',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [281, 628, 381, 719]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '007',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [597, 305, 631, 387]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '008',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [324, 0, 387, 143]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '009',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [480, 109, 520, 193]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '010',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [479, 50, 520, 195]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '011',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [543, 294, 590, 382]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '012',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [433, 89, 480, 172]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '013',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [381, 65, 436, 153]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '014',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [519, 401, 566, 560]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '015',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [294, 281, 395, 359]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '016',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [565, 474, 599, 552]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '017',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [174, 274, 295, 346]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '018',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [433, 26, 480, 179]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '019',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [450, 500, 506, 569]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '020',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [517, 133, 547, 206]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '021',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [381, 0, 437, 163]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '022',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [520, 474, 566, 550]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '023',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [564, 403, 600, 555]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '024',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [299, 209, 399, 293]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '025',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [178, 199, 302, 288]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '026',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [383, 503, 450, 580]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '027',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [632, 315, 668, 391]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '028',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [593, 175, 632, 239]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '029',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [452, 436, 508, 500]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '030',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [300, 507, 383, 591]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '031',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [458, 249, 513, 373]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '032',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [306, 432, 387, 509]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '033',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [458, 309, 511, 373]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '034',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [634, 192, 666, 252]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '035',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [596, 406, 630, 549]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '036',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [332, 0, 386, 55]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '037',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [657, 634, 689, 694]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '038',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [450, 436, 508, 569]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '039',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [524, 0, 588, 72]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '040',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [460, 248, 513, 317]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '041',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [174, 200, 303, 346]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '042',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [582, 657, 621, 719]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '043',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [690, 626, 717, 681]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '044',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [386, 434, 452, 505]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '045',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [393, 296, 457, 366]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '046',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [589, 0, 624, 65]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '047',\n",
              "  'target_class': 'toiletpaper',\n",
              "  'target_bbox': [808, 262, 869, 327]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '048',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [397, 230, 460, 305]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '049',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [388, 4, 436, 78]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '050',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [509, 607, 581, 682]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '051',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [650, 581, 689, 640]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '052',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [572, 598, 621, 664]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '053',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [589, 45, 624, 95]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '054',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [393, 230, 460, 366]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '055',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [297, 209, 399, 359]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '056',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [609, 589, 657, 701]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '057',\n",
              "  'target_class': 'tilecleaner',\n",
              "  'target_bbox': [700, 306, 732, 399]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '058',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [683, 70, 708, 118]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '059',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [534, 671, 580, 719]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '060',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [713, 571, 741, 620]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '061',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [180, 511, 303, 606]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '062',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [177, 428, 310, 515]},\n",
              " {'image_id': 1,\n",
              "  'annotation_id': '063',\n",
              "  'target_class': 'napkins',\n",
              "  'target_bbox': [383, 434, 453, 579]}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGOfba8Ape2J"
      },
      "source": [
        "#Downloading dataset from roboflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cT4WfKKh4ww",
        "outputId": "b7ef6e97-9220-4e9a-a879-3ecf3e0fcf31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Supermercado-2 to yolov5pytorch: 99% [234160128 / 235134714] bytes"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"6SD3lhyA7O38SGwWUNX2\")\n",
        "project = rf.workspace(\"deeplearning-qyswt\").project(\"supermercado-kuezz\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK-Lip7fh968"
      },
      "outputs": [],
      "source": [
        "import os, glob,cv2\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG0-gSm-iDJ2"
      },
      "outputs": [],
      "source": [
        "def save_patch(patch, save_path, id, file_body):\n",
        "  patch_path = f\"{save_path}/{id}_{file_body}.jpg\"\n",
        "  if not os.path.isdir(save_path):\n",
        "    os.makedirs(save_path)\n",
        "  else:\n",
        "    pass\n",
        "  cv2.imwrite(patch_path, patch)\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuCv2YkQiALe"
      },
      "outputs": [],
      "source": [
        "def bbox_formatter(bbox, format, img_height, img_width):\n",
        "  if format == 'yolo-norm':\n",
        "    center_x,center_y, bb_width, bb_height = bbox\n",
        "    x, y, h, w = float(center_x)*img_width, float(center_y)*img_height, float(bb_height)*img_height, float(bb_width)*img_width\n",
        "    crop_coords = int(y-h/2), int(y+h/2), int(x-w/2),int(x+w/2)\n",
        "  # add any other format\n",
        "  else:\n",
        "    crop_coords = bbox\n",
        "  return crop_coords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjx1n7WCiTs0"
      },
      "outputs": [],
      "source": [
        "def encoder(base_path):\n",
        "  encoding_map = imgencoder.encode_images(image_dir=base_path+'/Bases')\n",
        "\n",
        "  lbl_dict = defaultdict(list)\n",
        "  for k,v in encoding_map.items():\n",
        "    lbl = k.split('-')[0]\n",
        "    lbl_dict[lbl].append(v)\n",
        "  return lbl_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt7ngKVXjqtm"
      },
      "outputs": [],
      "source": [
        "def get_labels(lbl_dict):\n",
        "  labels, feats = [], []\n",
        "  for l, fs in lbl_dict.items():\n",
        "    labels.append(l)\n",
        "    feats.append(np.array(fs).mean(axis=0))\n",
        "  color_dict = dict(zip(labels, ['b','r','g','w']))\n",
        "  return labels,feats,color_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_SdkDDQq-WE",
        "outputId": "36afd4cf-e340-415d-d71b-9cee470e907a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<module 'posixpath' from '/usr/lib/python3.10/posixpath.py'>\n"
          ]
        }
      ],
      "source": [
        "print(os.path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSVeiahdjCcJ"
      },
      "source": [
        "#**sample check for one Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT-weDg9SYKU"
      },
      "outputs": [],
      "source": [
        "dataset_dir = \"/content/weights/Supermercado-2/train/images/Image0_png.rf.318507b51f5d126fa0ccd286f2ad1130.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "4kUmRZZyR9T5",
        "outputId": "c69a6aa5-366c-4295-bbbd-fb5e830a754e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-29 17:13:24,529: INFO Device set to cpu ..\n",
            "INFO:imagededup.methods.cnn:Device set to cpu ..\n",
            "2023-08-29 17:13:24,542: INFO Initialized: mobilenet_v3_small for feature extraction ..\n",
            "INFO:imagededup.methods.cnn:Initialized: mobilenet_v3_small for feature extraction ..\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1ed84cc965ca>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoding_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Bases'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlbl_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imagededup/methods/cnn.py\u001b[0m in \u001b[0;36mencode_images\u001b[0;34m(self, image_dir, recursive, num_enc_workers)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide a valid directory path!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_enc_workers\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"linux\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide a valid directory path!"
          ]
        }
      ],
      "source": [
        "imgencoder = CNN()\n",
        "encoding_map = imgencoder.encode_images(image_dir=base_path+'/Bases')\n",
        "\n",
        "lbl_dict = defaultdict(list)\n",
        "for k,v in encoding_map.items():\n",
        "  lbl = k.split('-')[0]\n",
        "  lbl_dict[lbl].append(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "rSdkKBYUSACV",
        "outputId": "2835dc38-6646-40f0-bb68-12ccdbdebb99"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8233f24f6b52>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ],
      "source": [
        "color_dict = dict(zip(labels, ['b','r','g','w']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbu1AD-ETlWf"
      },
      "outputs": [],
      "source": [
        "def detect_objectsS(image, model):\n",
        "  # generate segmentations\n",
        "  start = time.perf_counter()\n",
        "  print(\"start\")\n",
        "  sam_result = model.generate(image)\n",
        "  print(f\"Time taken for inference: {time.perf_counter()-start} milli. sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAEwUEKaUAV1"
      },
      "outputs": [],
      "source": [
        "image_rgb = load_image(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "QSZhHMvBT44a",
        "outputId": "8ae42d65-7d8f-48a9-ebc8-662a985f6cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-2a70cd1101f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetect_objectsS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-abb554e8a680>\u001b[0m in \u001b[0;36mdetect_objectsS\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0msam_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time taken for inference: {time.perf_counter()-start} milli. sec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Generate masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mmask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Filter small disconnected regions and holes in masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36m_generate_masks\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcrop_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mcrop_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36m_process_crop\u001b[0;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_per_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_for_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropped_im_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, points, im_size, crop_box, orig_size)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0min_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0min_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         masks, iou_preds, _ = self.predictor.predict_torch(\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0min_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0min_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/predictor.py\u001b[0m in \u001b[0;36mpredict_torch\u001b[0;34m(self, point_coords, point_labels, boxes, mask_input, multimask_output, return_logits)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Predict masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         low_res_masks, iou_predictions = self.model.mask_decoder(\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mimage_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mimage_pe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dense_pe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/mask_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output)\u001b[0m\n\u001b[1;32m     92\u001b[0m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmask\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         masks, iou_pred = self.predict_masks(\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mimage_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mimage_pe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_pe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/mask_decoder.py\u001b[0m in \u001b[0;36mpredict_masks\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Run the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0miou_token_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mmask_tokens_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_mask_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_embedding, image_pe, point_embedding)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Apply transformer blocks and final layernorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             queries, keys = layer(\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, keys, query_pe, key_pe)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery_pe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey_pe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_token_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1599\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "detect_objectsS(image_rgb,mask_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RiKmbuXjNF-"
      },
      "source": [
        "#**INFERENCING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFyr532yrUA1"
      },
      "outputs": [],
      "source": [
        "dataset_dir = \"/content/weights/Supermercado-2/train/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5qV9A9KvcyS",
        "outputId": "19f68981-8f09-4ef2-ad3e-7a9112d2622c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-06 12:32:00,181: INFO Start: Image encoding generation\n",
            "INFO:imagededup.methods.cnn:Start: Image encoding generation\n",
            "2023-09-06 12:32:00,518: INFO End: Image encoding generation\n",
            "INFO:imagededup.methods.cnn:End: Image encoding generation\n"
          ]
        }
      ],
      "source": [
        "lbl_dict = encoder(base_path)\n",
        "\n",
        "labels, feats, color_dict = get_labels(lbl_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "azfzCFnZYn4x",
        "outputId": "39877f93-8615-4222-b876-c7e49b557a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken for inference: 593.8670176169999 milli. sec\n",
            "Time taken for inference: 570.412361362 milli. sec\n",
            "Time taken for inference: 590.5243396449996 milli. sec\n",
            "Time taken for inference: 577.0538897870001 milli. sec\n",
            "Time taken for inference: 585.1289331099997 milli. sec\n",
            "Time taken for inference: 564.1990066449998 milli. sec\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "output_dir = \"/content/inferenced\"\n",
        "\n",
        "images_info = []\n",
        "\n",
        "# Ensure the output directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for root, _, filenames in os.walk(dataset_dir):\n",
        "    count=0\n",
        "    annotations=[]\n",
        "    images_info=[]\n",
        "    for filename in filenames:\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            count+=1\n",
        "            images_info.append({\n",
        "            \"image_id\": count,\n",
        "            \"image_path\": dataset_dir+filename\n",
        "            })\n",
        "            image_path = os.path.join(root, filename)\n",
        "\n",
        "            image_rgb = load_image(image_path)\n",
        "\n",
        "\n",
        "            # Perform object detection using your detect_objects function\n",
        "            annotation=detect_objects(image_rgb, mask_generator, imgencoder, labels, feats, color_dict, thr=0.76)\n",
        "            annotations.append(annotation)\n",
        "\n",
        "            # Save the annotated image directly to the /content directory\n",
        "            #output_path = os.path.join(output_dir, filename)\n",
        "            #cv2.imwrite(output_path, image_rgb\n",
        "\n",
        "    result = {\n",
        "    \"images\": images_info,\n",
        "    \"annotations\": annotations\n",
        "    }\n",
        "\n",
        "    result_json = json.dumps(result, indent=4)\n",
        "print(result_json)\n",
        "print(\"Inference on all images complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vni97_h3vPTI",
        "outputId": "ab4cf6be-80d0-4ed5-8201-40ff4454b5fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"images\": [\n",
            "        {\n",
            "            \"image_id\": 1,\n",
            "            \"image_path\": \"/content/weights/Supermercado-2/train/imagesImage432_png.rf.eb078b3958d45eebb0becb1e9a5934a9.jpg\"\n",
            "        }\n",
            "    ],\n",
            "    \"annotations\": [\n",
            "        {\n",
            "            \"image_id\": 1,\n",
            "            \"annotation_id\": \"001\",\n",
            "            \"target_class\": \"toiletpaper\",\n",
            "            \"target_bbox\": [\n",
            "                224,\n",
            "                229,\n",
            "                308,\n",
            "                343\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"image_id\": 1,\n",
            "            \"annotation_id\": \"002\",\n",
            "            \"target_class\": \"wax\",\n",
            "            \"target_bbox\": [\n",
            "                160,\n",
            "                102,\n",
            "                228,\n",
            "                179\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"image_id\": 1,\n",
            "            \"annotation_id\": \"003\",\n",
            "            \"target_class\": \"wax\",\n",
            "            \"target_bbox\": [\n",
            "                578,\n",
            "                326,\n",
            "                605,\n",
            "                349\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"image_id\": 1,\n",
            "            \"annotation_id\": \"004\",\n",
            "            \"target_class\": \"wax\",\n",
            "            \"target_bbox\": [\n",
            "                141,\n",
            "                8,\n",
            "                218,\n",
            "                97\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(result_json)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lSVeiahdjCcJ"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}