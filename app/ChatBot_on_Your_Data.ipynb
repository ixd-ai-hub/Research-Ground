{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixd-ai-hub/Research-Ground/blob/project%2FCU-865d7n88b-chatbot-creator/app/ChatBot_on_Your_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpK-m2Kows4I"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install unstructured\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken\n",
        "!pip install unstructured[local-inference]\n",
        "!pip install --ignore-installed Pillow==9.0.0\n",
        "!pip install docx2txt\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install tesseract"
      ],
      "metadata": {
        "id": "JPKC-mYUnEyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y1vzDgtxBwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae027422-450b-433c-9a70-b4c9bede0bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "XdSH2mqVjnLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx0hV4ZqxJD4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import textwrap\n",
        "import chromadb\n",
        "import gradio as gr\n",
        "\n",
        "from langchain.document_loaders import TextLoader, UnstructuredPowerPointLoader, UnstructuredPDFLoader, UnstructuredHTMLLoader, Docx2txtLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS, Chroma\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0CR7zfIy-bV"
      },
      "source": [
        "## Working with pdf, txt, pptx, html, docx Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7cIdFfhyz45"
      },
      "outputs": [],
      "source": [
        "def fileReader(txt_path, load=False):\n",
        "    loader = UnstructuredPDFLoader(txt_path)\n",
        "    if load == True:\n",
        "      document = loader.load()\n",
        "      return document\n",
        "    else:\n",
        "      return loader\n",
        "\n",
        "def fileDocs(data_path, load=False):\n",
        "    ext = data_path.split('.')[-1]\n",
        "    if ext == 'pdf':\n",
        "        docs = [UnstructuredPDFLoader(data_path)]\n",
        "    elif ext == 'txt':\n",
        "        docs = [TextLoader(data_path)]\n",
        "    elif ext == 'pptx':\n",
        "        docs = [UnstructuredPowerPointLoader(data_path)]\n",
        "    elif ext == 'html':\n",
        "        docs = [UnstructuredHTMLLoader(data_path)]\n",
        "    elif ext == 'docx':\n",
        "        docs = [Docx2txtLoader(data_path)]\n",
        "\n",
        "    return docs\n",
        "\n",
        "def fileData(data_path):\n",
        "  docs = fileDocs(data_path, load=True)[0]\n",
        "  text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "  data = text_splitter.split_documents(docs)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfsiCvqb0njx"
      },
      "outputs": [],
      "source": [
        "PDF_PATH = '/content/gdrive/MyDrive/PDFs/2203.03605.pdf'\n",
        "# PDF_PATH = '/content/gdrive/MyDrive/PDFs'\n",
        "pdf_docs = fileDocs(PDF_PATH)\n",
        "# pdf_data = pdfData(pdf_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cvhM_Oa010X",
        "outputId": "5a30b4b4-7199-40c1-d2de-3f87c570b2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with another strategy.\n",
            "WARNING:unstructured:Falling back to partitioning with ocr_only.\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1042, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1661, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1552, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1054, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1054, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1061, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1154, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1530, which is longer than the specified 1000\n",
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ],
      "source": [
        "pdfindex = VectorstoreIndexCreator(\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(pdf_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ksrh-iN1K_F"
      },
      "outputs": [],
      "source": [
        "llm=OpenAI()\n",
        "chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=pdfindex.vectorstore.as_retriever(),\n",
        "                                    input_key=\"question\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KnC-zxC01KSv",
        "outputId": "8e555632-6b04-4d6e-d35d-9fc62b22469d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The DINO model was inspired by DN-DETR [17], DAB-DETR [21], and Deformable DETR [41], with novel techniques such as contrastive DN training, mixed query selection, and look forward twice for different parts of the model.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chain.run('give inspiration for the DINO model ?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "YUT5Tjw_1-HY",
        "outputId": "585dee53-484f-469b-888e-1e3f18d4b8c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The highlights of the DINO model are its use of contrastive denoising training, mixed query selection, and look forward twice schemes, which improve both training efficiency and detection performance. The model has achieved a 49.4AP in 12 epochs, 51.3AP in 24 epochs with ResNet-50 and multi-scale features on the COCO val2017 benchmark, and 63.3 AP on the COCO 2017 test-dev benchmark. Compared to other models on the leaderboard, DINO significantly reduces its model size and pre-training data size while achieving better results.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "chain.run('What are the highlights of DINO model?')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "umw6-tH_rGma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI()\n",
        "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
        "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "\n",
        "chain = ConversationalRetrievalChain(\n",
        "    retriever=pdfindex.vectorstore.as_retriever(),\n",
        "    question_generator=question_generator,\n",
        "    combine_docs_chain=doc_chain,\n",
        ")"
      ],
      "metadata": {
        "id": "jllG7379q-1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"what are the inspirations for the DINO model ?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "result['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6LsBuzDgq-tv",
        "outputId": "799f824f-ee69-4465-bec8-5d58d44ba532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The inspirations for the DINO model include DN-DETR, DAB-DETR, Deformable DETR, a backbone, a multi-layer Transformer encoder, a multi-layer Transformer decoder, and multiple prediction heads. \\nSOURCES: /content/gdrive/MyDrive/PDFs/2203.03605.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what are the datasets used in the model training?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "result['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eC5j2Rhuqv61",
        "outputId": "74ea5d27-c2f6-421d-86b0-b240fe10e690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The datasets used in the model training are IN, Objects365, SwinL, Soft Teacher+SwinL, IP, Florence-CoSwin-H, SwinV2-G and DINO-SwinL.\\nSOURCES: /content/gdrive/MyDrive/PDFs/2203.03605.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "MoqcW2gF12l3",
        "outputId": "d5e82abb-ee7c-4d16-f859-7eb3be365f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with another strategy.\n",
            "WARNING:unstructured:Falling back to partitioning with ocr_only.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file name : /tmp/gradio/56dfb6357871393613c0b9cc36724ebf75818854/careers_keells_com_job_Colombo_Data_Scientist_Octave_Data_an.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def add_text(history, text):\n",
        "    history = history + [(text, None)]\n",
        "    return history, \"\"\n",
        "\n",
        "pdfindex = None\n",
        "llm=OpenAI()\n",
        "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
        "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
        "chat_history = []\n",
        "chain = None\n",
        "\n",
        "def add_file(history, file):\n",
        "    global pdfindex, chain, chat_history\n",
        "    print(\"file name :\", file.name)\n",
        "    if file.name:\n",
        "      fname = file.name\n",
        "    else:\n",
        "      fname = '/content/gdrive/MyDrive/PDFs/state_of_the_union.txt'\n",
        "\n",
        "    pdf_docs = fileDocs(fname)\n",
        "    pdfindex = VectorstoreIndexCreator(embedding=OpenAIEmbeddings(), text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(pdf_docs)\n",
        "    doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
        "    chain = ConversationalRetrievalChain(\n",
        "        retriever=pdfindex.vectorstore.as_retriever(),\n",
        "        question_generator=question_generator,\n",
        "        combine_docs_chain=doc_chain,\n",
        "    )\n",
        "    chat_history = [] # previos history wipe-out\n",
        "    history = history + [(\"upload File\", None)]\n",
        "    return history\n",
        "\n",
        "def bot(history):\n",
        "    global chain, chat_history\n",
        "    # response = \"**That's cool!**\"\n",
        "    query = history[-1][0]\n",
        "    if query != 'upload File':\n",
        "      response = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "      asnwer = response['answer'].split('\\nSOURCES')[0]\n",
        "      history[-1][1] = asnwer\n",
        "    else:\n",
        "      history[-1][1] = \"The uploaded file now in the processing!\"\n",
        "    return history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot([], elem_id=\"chatbot\").style(height=400)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=0.85):\n",
        "            txt = gr.Textbox(\n",
        "                show_label=False,\n",
        "                placeholder=\"Enter text and press enter, or upload an image\",\n",
        "            ).style(container=False)\n",
        "        with gr.Column(scale=0.15, min_width=0):\n",
        "            btn = gr.UploadButton(\"ðŸ“\", file_types=[\"file\"])\n",
        "\n",
        "    txt.submit(add_text, [chatbot, txt], [chatbot, txt]).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "    btn.upload(add_file, [chatbot, btn], [chatbot]).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True, show_error=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT2zGGh1CY2e"
      },
      "source": [
        "---\n",
        "## Working with URL files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"playwright\"\n",
        "!pip install \"unstructured\"\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "GyoTGl81XMfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6493dbd3-7ad0-4d81-ad2f-cde42c336757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting playwright\n",
            "  Downloading playwright-1.33.0-py3-none-manylinux1_x86_64.whl (35.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyee==9.0.4\n",
            "  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\n",
            "Collecting greenlet==2.0.1\n",
            "  Downloading greenlet-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (539 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m539.9/539.9 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee==9.0.4->playwright) (4.5.0)\n",
            "Installing collected packages: pyee, greenlet, playwright\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 2.0.2\n",
            "    Uninstalling greenlet-2.0.2:\n",
            "      Successfully uninstalled greenlet-2.0.2\n",
            "Successfully installed greenlet-2.0.1 playwright-1.33.0 pyee-9.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "greenlet"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.6.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.11)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.30.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (9.5.0)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.21)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2022.12.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.2)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured) (20221105)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.11)\n",
            "Requirement already satisfied: argilla in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.6.0)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Requirement already satisfied: deprecated~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.2.13)\n",
            "Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (23.1)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.6)\n",
            "Requirement already satisfied: rich<=13.0.1 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (13.0.1)\n",
            "Requirement already satisfied: httpx<0.24,>=0.15 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.23.3)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (2.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from msg-parser->unstructured) (0.46)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (40.0.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx->unstructured) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.6.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
            "Downloading Chromium 113.0.5672.53 (playwright build v1060)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1060/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G144.6 Mb [] 0% 0.0s\u001b[0K\u001b[1G144.6 Mb [] 0% 4.8s\u001b[0K\u001b[1G144.6 Mb [] 1% 2.2s\u001b[0K\u001b[1G144.6 Mb [] 2% 1.8s\u001b[0K\u001b[1G144.6 Mb [] 3% 1.7s\u001b[0K\u001b[1G144.6 Mb [] 4% 1.7s\u001b[0K\u001b[1G144.6 Mb [] 5% 1.6s\u001b[0K\u001b[1G144.6 Mb [] 7% 1.4s\u001b[0K\u001b[1G144.6 Mb [] 9% 1.2s\u001b[0K\u001b[1G144.6 Mb [] 10% 1.2s\u001b[0K\u001b[1G144.6 Mb [] 11% 1.2s\u001b[0K\u001b[1G144.6 Mb [] 13% 1.1s\u001b[0K\u001b[1G144.6 Mb [] 14% 1.1s\u001b[0K\u001b[1G144.6 Mb [] 16% 1.1s\u001b[0K\u001b[1G144.6 Mb [] 17% 1.1s\u001b[0K\u001b[1G144.6 Mb [] 19% 1.0s\u001b[0K\u001b[1G144.6 Mb [] 21% 1.0s\u001b[0K\u001b[1G144.6 Mb [] 22% 1.0s\u001b[0K\u001b[1G144.6 Mb [] 23% 1.0s\u001b[0K\u001b[1G144.6 Mb [] 24% 0.9s\u001b[0K\u001b[1G144.6 Mb [] 26% 0.9s\u001b[0K\u001b[1G144.6 Mb [] 27% 0.9s\u001b[0K\u001b[1G144.6 Mb [] 29% 0.8s\u001b[0K\u001b[1G144.6 Mb [] 31% 0.8s\u001b[0K\u001b[1G144.6 Mb [] 32% 0.8s\u001b[0K\u001b[1G144.6 Mb [] 34% 0.8s\u001b[0K\u001b[1G144.6 Mb [] 36% 0.7s\u001b[0K\u001b[1G144.6 Mb [] 37% 0.7s\u001b[0K\u001b[1G144.6 Mb [] 39% 0.7s\u001b[0K\u001b[1G144.6 Mb [] 42% 0.6s\u001b[0K\u001b[1G144.6 Mb [] 43% 0.6s\u001b[0K\u001b[1G144.6 Mb [] 45% 0.6s\u001b[0K\u001b[1G144.6 Mb [] 47% 0.6s\u001b[0K\u001b[1G144.6 Mb [] 50% 0.5s\u001b[0K\u001b[1G144.6 Mb [] 52% 0.5s\u001b[0K\u001b[1G144.6 Mb [] 54% 0.5s\u001b[0K\u001b[1G144.6 Mb [] 56% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 58% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 60% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 62% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 63% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 64% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 66% 0.4s\u001b[0K\u001b[1G144.6 Mb [] 68% 0.3s\u001b[0K\u001b[1G144.6 Mb [] 70% 0.3s\u001b[0K\u001b[1G144.6 Mb [] 72% 0.3s\u001b[0K\u001b[1G144.6 Mb [] 74% 0.3s\u001b[0K\u001b[1G144.6 Mb [] 76% 0.2s\u001b[0K\u001b[1G144.6 Mb [] 79% 0.2s\u001b[0K\u001b[1G144.6 Mb [] 81% 0.2s\u001b[0K\u001b[1G144.6 Mb [] 83% 0.2s\u001b[0K\u001b[1G144.6 Mb [] 85% 0.1s\u001b[0K\u001b[1G144.6 Mb [] 87% 0.1s\u001b[0K\u001b[1G144.6 Mb [] 90% 0.1s\u001b[0K\u001b[1G144.6 Mb [] 92% 0.1s\u001b[0K\u001b[1G144.6 Mb [] 94% 0.0s\u001b[0K\u001b[1G144.6 Mb [] 97% 0.0s\u001b[0K\u001b[1G144.6 Mb [] 100% 0.0s\u001b[0K\n",
            "Chromium 113.0.5672.53 (playwright build v1060) downloaded to /root/.cache/ms-playwright/chromium-1060\n",
            "Downloading FFMPEG playwright build v1008\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1008/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.6 Mb [] 0% 0.0s\u001b[0K\u001b[1G2.6 Mb [] 24% 0.0s\u001b[0K\u001b[1G2.6 Mb [] 92% 0.0s\u001b[0K\u001b[1G2.6 Mb [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1008 downloaded to /root/.cache/ms-playwright/ffmpeg-1008\n",
            "Downloading Firefox 112.0 (playwright build v1403)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1403/firefox-ubuntu-20.04.zip\u001b[22m\n",
            "\u001b[1G79 Mb [] 0% 0.0s\u001b[0K\u001b[1G79 Mb [] 0% 3.4s\u001b[0K\u001b[1G79 Mb [] 2% 1.3s\u001b[0K\u001b[1G79 Mb [] 5% 0.9s\u001b[0K\u001b[1G79 Mb [] 7% 0.9s\u001b[0K\u001b[1G79 Mb [] 8% 0.9s\u001b[0K\u001b[1G79 Mb [] 11% 0.8s\u001b[0K\u001b[1G79 Mb [] 13% 0.7s\u001b[0K\u001b[1G79 Mb [] 17% 0.6s\u001b[0K\u001b[1G79 Mb [] 20% 0.6s\u001b[0K\u001b[1G79 Mb [] 24% 0.5s\u001b[0K\u001b[1G79 Mb [] 26% 0.5s\u001b[0K\u001b[1G79 Mb [] 29% 0.5s\u001b[0K\u001b[1G79 Mb [] 31% 0.5s\u001b[0K\u001b[1G79 Mb [] 34% 0.4s\u001b[0K\u001b[1G79 Mb [] 38% 0.4s\u001b[0K\u001b[1G79 Mb [] 41% 0.4s\u001b[0K\u001b[1G79 Mb [] 45% 0.3s\u001b[0K\u001b[1G79 Mb [] 48% 0.3s\u001b[0K\u001b[1G79 Mb [] 50% 0.3s\u001b[0K\u001b[1G79 Mb [] 52% 0.3s\u001b[0K\u001b[1G79 Mb [] 55% 0.3s\u001b[0K\u001b[1G79 Mb [] 58% 0.3s\u001b[0K\u001b[1G79 Mb [] 61% 0.2s\u001b[0K\u001b[1G79 Mb [] 63% 0.2s\u001b[0K\u001b[1G79 Mb [] 67% 0.2s\u001b[0K\u001b[1G79 Mb [] 71% 0.2s\u001b[0K\u001b[1G79 Mb [] 74% 0.2s\u001b[0K\u001b[1G79 Mb [] 76% 0.1s\u001b[0K\u001b[1G79 Mb [] 79% 0.1s\u001b[0K\u001b[1G79 Mb [] 80% 0.1s\u001b[0K\u001b[1G79 Mb [] 83% 0.1s\u001b[0K\u001b[1G79 Mb [] 86% 0.1s\u001b[0K\u001b[1G79 Mb [] 89% 0.1s\u001b[0K\u001b[1G79 Mb [] 93% 0.0s\u001b[0K\u001b[1G79 Mb [] 97% 0.0s\u001b[0K\u001b[1G79 Mb [] 100% 0.0s\u001b[0K\n",
            "Firefox 112.0 (playwright build v1403) downloaded to /root/.cache/ms-playwright/firefox-1403\n",
            "Downloading Webkit 16.4 (playwright build v1837)\u001b[2m from https://playwright.azureedge.net/builds/webkit/1837/webkit-ubuntu-20.04.zip\u001b[22m\n",
            "\u001b[1G79.5 Mb [] 0% 0.0s\u001b[0K\u001b[1G79.5 Mb [] 0% 6.7s\u001b[0K\u001b[1G79.5 Mb [] 1% 1.9s\u001b[0K\u001b[1G79.5 Mb [] 3% 1.4s\u001b[0K\u001b[1G79.5 Mb [] 4% 1.3s\u001b[0K\u001b[1G79.5 Mb [] 6% 1.2s\u001b[0K\u001b[1G79.5 Mb [] 7% 1.2s\u001b[0K\u001b[1G79.5 Mb [] 8% 1.3s\u001b[0K\u001b[1G79.5 Mb [] 10% 1.1s\u001b[0K\u001b[1G79.5 Mb [] 13% 1.0s\u001b[0K\u001b[1G79.5 Mb [] 15% 0.9s\u001b[0K\u001b[1G79.5 Mb [] 18% 0.8s\u001b[0K\u001b[1G79.5 Mb [] 20% 0.8s\u001b[0K\u001b[1G79.5 Mb [] 23% 0.7s\u001b[0K\u001b[1G79.5 Mb [] 25% 0.7s\u001b[0K\u001b[1G79.5 Mb [] 27% 0.7s\u001b[0K\u001b[1G79.5 Mb [] 30% 0.6s\u001b[0K\u001b[1G79.5 Mb [] 31% 0.6s\u001b[0K\u001b[1G79.5 Mb [] 34% 0.6s\u001b[0K\u001b[1G79.5 Mb [] 36% 0.5s\u001b[0K\u001b[1G79.5 Mb [] 38% 0.5s\u001b[0K\u001b[1G79.5 Mb [] 40% 0.5s\u001b[0K\u001b[1G79.5 Mb [] 43% 0.5s\u001b[0K\u001b[1G79.5 Mb [] 45% 0.5s\u001b[0K\u001b[1G79.5 Mb [] 46% 0.5s\u001b[0K\u001b[1G79.5 Mb [] 49% 0.4s\u001b[0K\u001b[1G79.5 Mb [] 53% 0.4s\u001b[0K\u001b[1G79.5 Mb [] 55% 0.4s\u001b[0K\u001b[1G79.5 Mb [] 57% 0.4s\u001b[0K\u001b[1G79.5 Mb [] 58% 0.3s\u001b[0K\u001b[1G79.5 Mb [] 60% 0.3s\u001b[0K\u001b[1G79.5 Mb [] 61% 0.3s\u001b[0K\u001b[1G79.5 Mb [] 63% 0.3s\u001b[0K\u001b[1G79.5 Mb [] 66% 0.3s\u001b[0K\u001b[1G79.5 Mb [] 69% 0.3s\u001b[0K\u001b[1G79.5 Mb [] 71% 0.2s\u001b[0K\u001b[1G79.5 Mb [] 73% 0.2s\u001b[0K\u001b[1G79.5 Mb [] 75% 0.2s\u001b[0K\u001b[1G79.5 Mb [] 78% 0.2s\u001b[0K\u001b[1G79.5 Mb [] 79% 0.2s\u001b[0K\u001b[1G79.5 Mb [] 82% 0.1s\u001b[0K\u001b[1G79.5 Mb [] 85% 0.1s\u001b[0K\u001b[1G79.5 Mb [] 89% 0.1s\u001b[0K\u001b[1G79.5 Mb [] 92% 0.1s\u001b[0K\u001b[1G79.5 Mb [] 95% 0.0s\u001b[0K\u001b[1G79.5 Mb [] 98% 0.0s\u001b[0K\u001b[1G79.5 Mb [] 100% 0.0s\u001b[0K\n",
            "Webkit 16.4 (playwright build v1837) downloaded to /root/.cache/ms-playwright/webkit-1837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZlg56CVNYrq",
        "outputId": "0bfc8479-cab3-4ee2-d8bc-2114179e04ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.9.0-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.15)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Installing collected packages: wsproto, outcome, async-generator, trio, trio-websocket, selenium\n",
            "Successfully installed async-generator-1.10 outcome-1.2.0 selenium-4.9.0 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIDr5aElROTV",
        "outputId": "dfd87279-8f88-48f4-a402-60c278c2b443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r                                                                    \r0% [Waiting for headers] [Waiting for headers]\r                                              \rGet:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r0% [4 InRelease 14.2 kB/114 kB 12%] [Waiting for headers] [Waiting for headers]\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r0% [4 InRelease 89.5 kB/114 kB 79%] [5 InRelease 14.2 kB/114 kB 12%] [Waiting f\r                                                                               \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,009 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,669 kB]\n",
            "Fetched 7,169 kB in 2s (4,482 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser liblzo2-2 libudev1 snapd squashfs-tools udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver liblzo2-2 snapd\n",
            "  squashfs-tools udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 7 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 40.0 MB of archives.\n",
            "After this operation, 183 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apparmor amd64 2.13.3-7ubuntu5.2 [502 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 squashfs-tools amd64 1:4.4-1ubuntu0.3 [117 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libudev1 amd64 245.4-4ubuntu3.21 [75.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 udev amd64 245.4-4ubuntu3.21 [1,366 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 snapd amd64 2.58+20.04 [37.9 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [48.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [2,496 B]\n",
            "Fetched 40.0 MB in 1s (54.8 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_2.13.3-7ubuntu5.2_amd64.deb ...\n",
            "Unpacking apparmor (2.13.3-7ubuntu5.2) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.4-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.4-1ubuntu0.3) ...\n",
            "Preparing to unpack .../libudev1_245.4-4ubuntu3.21_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (245.4-4ubuntu3.21) over (245.4-4ubuntu3.19) ...\n",
            "Setting up libudev1:amd64 (245.4-4ubuntu3.21) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 122705 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_245.4-4ubuntu3.21_amd64.deb ...\n",
            "Unpacking udev (245.4-4ubuntu3.21) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.58+20.04_amd64.deb ...\n",
            "Unpacking snapd (2.58+20.04) ...\n",
            "Setting up apparmor (2.13.3-7ubuntu5.2) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service â†’ /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2) ...\n",
            "Setting up squashfs-tools (1:4.4-1ubuntu0.3) ...\n",
            "Setting up udev (245.4-4ubuntu3.21) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up snapd (2.58+20.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.aa-prompt-listener.service â†’ /lib/systemd/system/snapd.aa-prompt-listener.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service â†’ /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service â†’ /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service â†’ /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service â†’ /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service â†’ /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service â†’ /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service â†’ /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer â†’ /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket â†’ /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service â†’ /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 122926 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for systemd (245.4-4ubuntu3.21) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for dbus (1.12.16-2ubuntu2.3) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2fhNEy_CYKo"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import SeleniumURLLoader\n",
        "from langchain.document_loaders import PlaywrightURLLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JQw1bju6ConI",
        "outputId": "e0f5665d-0126-4285-ca72-ecd3623bd873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trio/_core/_multierror.py:406: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 412, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1299, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1021, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-16-20c8ec7e1337>\", line 23, in bot\n",
            "    response = chain.run(query)\n",
            "AttributeError: 'NoneType' object has no attribute 'run'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 412, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1299, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1021, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-16-20c8ec7e1337>\", line 13, in add_file\n",
            "    pdfindex = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings(), text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(html_docs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/indexes/vectorstore.py\", line 72, in from_loaders\n",
            "    docs.extend(loader.load())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/document_loaders/url_playwright.py\", line 62, in load\n",
            "    with sync_playwright() as p:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/playwright/sync_api/_context_manager.py\", line 93, in __enter__\n",
            "    playwright = self._playwright\n",
            "AttributeError: 'PlaywrightContextManager' object has no attribute '_playwright'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def add_text(history, text):\n",
        "    history = history + [(text, None)]\n",
        "    return history, \"\"\n",
        "\n",
        "pdfindex = None\n",
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-small\", model_kwargs={\"temperature\":0.2, \"max_length\":512})\n",
        "chain = None\n",
        "\n",
        "def add_file(history, url):\n",
        "    global pdfindex, chain\n",
        "\n",
        "    html_docs = [PlaywrightURLLoader(urls=[url])]\n",
        "    pdfindex = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings(), text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(html_docs)\n",
        "    chain = RetrievalQA.from_chain_type(llm=llm,  chain_type=\"stuff\",  retriever=pdfindex.vectorstore.as_retriever(),  input_key=\"question\")\n",
        "    history = history + [(\"upload File\", None)]\n",
        "    return history\n",
        "\n",
        "def bot(history):\n",
        "    global chain\n",
        "    # response = \"**That's cool!**\"\n",
        "    query = history[-1][0]\n",
        "    if query != 'upload File':\n",
        "      response = chain.run(query)\n",
        "      history[-1][1] = response\n",
        "    else:\n",
        "      history[-1][1] = \"The WebSite is uploaded to database!\"\n",
        "    return history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot([], elem_id=\"chatbot\").style(height=400)\n",
        "    # msg = gr.Textbox()\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=0.75):\n",
        "            txt = gr.Textbox(\n",
        "                label='Message',\n",
        "                show_label=True,\n",
        "                placeholder=\"Enter text and press enter\",\n",
        "            ).style(container=False)\n",
        "        with gr.Column(scale=0.25):\n",
        "            msg = gr.Textbox(label='URL').style(container=False)\n",
        "            # url = gr.TextBox(label='url', show_label=True, placeholder=\"Enter url and press enter\",).style(container=False)\n",
        "\n",
        "    txt.submit(add_text, [chatbot, txt], [chatbot, txt]).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "    msg.submit(add_file, [chatbot, msg], [chatbot]).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True, show_error=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i42QmnP9Xvhm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOytvcxYFCjRVfqIi1x07QB",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}